{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#00693E; color:white; padding:20px; border-radius:10px; font-family:sans-serif; text-align:left;\">\n",
    "    <h1 style=\"margin-bottom:10px; font-weight:bold;\">Universidad de Antioquia</h1>\n",
    "    <h2 style=\"margin-bottom:15px; font-weight:bold;\">Especialización en Analítica y Ciencia de Datos</h2>\n",
    "    <h3 style=\"font-weight:normal; margin-bottom:20px;\">Estadística y Análisis Exploratorio</h3>\n",
    "    <p style=\"font-size:20px; font-weight:bold; margin-bottom:10px;\">Trabajo 3</p>\n",
    "    <p style=\"font-size:16px; margin-bottom:5px;\"><strong>Profesor:</strong> Javier Lozano</p>\n",
    "    <p style=\"font-size:16px;\"><strong>Integrantes:</strong> Andres Fonseca y Felipe Quinto</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dmba import stepwise_selection\n",
    "from dmba import AIC_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='laboral.csv'\n",
    "df=pd.read_csv(url,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Contexto**\n",
    "\n",
    "El jefe de personal de una agencia gubernamental administró cuatro pruebas de aptitud a cada uno de los 25 aspirantes a cargos administrativos en la agencia. Para el propósito del estudio, se aceptaron a todos los aspirantes para 25 posiciones independientemente de sus puntajes en las pruebas. Después de un período de prueba, cada aspirante fue evaluado en su habilidad de trabajo. El puntaje obtenido relativo a la habilidad laboral (Y) y los puntajes en las cuatro pruebas (X1, X2, X3, X4) están consignados en el archivo `laboral.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 1**\n",
    "\n",
    "Emplee el análisis de regresión lineal múltiple para obtener una ecuación de regresión estimada que sirva para pronosticar la habilidad laboral, dadas las demás variables (Xi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\varepsilon\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $Y$ es la variable dependiente (habilidad laboral).\n",
    "- $X_1, X_2, X_3, X_4$ son las variables predictoras (puntajes de las pruebas).\n",
    "- $\\beta_0$ es la ordenada al origen (intercepto).\n",
    "- $\\beta_1, \\beta_2, \\beta_3, \\beta_4$ son los coeficientes de regresión asociados a cada predictor.\n",
    "- $\\varepsilon$ es el término de error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   129.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Oct 2024</td> <th>  Prob (F-statistic):</th> <td>5.26e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:36:37</td>     <th>  Log-Likelihood:    </th> <td> -67.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    25</td>      <th>  AIC:               </th> <td>   145.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   152.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    0.2957</td> <td>    0.044</td> <td>    6.725</td> <td> 0.000</td> <td>    0.204</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    0.0483</td> <td>    0.057</td> <td>    0.853</td> <td> 0.404</td> <td>   -0.070</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td>    1.3060</td> <td>    0.164</td> <td>    7.959</td> <td> 0.000</td> <td>    0.964</td> <td>    1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>    <td>    0.5198</td> <td>    0.132</td> <td>    3.940</td> <td> 0.001</td> <td>    0.245</td> <td>    0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -124.3818</td> <td>    9.941</td> <td>  -12.512</td> <td> 0.000</td> <td> -145.119</td> <td> -103.645</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.256</td> <th>  Durbin-Watson:     </th> <td>   1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.196</td> <th>  Jarque-Bera (JB):  </th> <td>   1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.139</td> <th>  Prob(JB):          </th> <td>   0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.867</td> <th>  Cond. No.          </th> <td>2.47e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.47e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        Y         & \\textbf{  R-squared:         } &     0.963   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.955   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     129.7   \\\\\n",
       "\\textbf{Date:}             & Fri, 04 Oct 2024 & \\textbf{  Prob (F-statistic):} &  5.26e-14   \\\\\n",
       "\\textbf{Time:}             &     22:36:37     & \\textbf{  Log-Likelihood:    } &   -67.951   \\\\\n",
       "\\textbf{No. Observations:} &          25      & \\textbf{  AIC:               } &     145.9   \\\\\n",
       "\\textbf{Df Residuals:}     &          20      & \\textbf{  BIC:               } &     152.0   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{X1}    &       0.2957  &        0.044     &     6.725  &         0.000        &        0.204    &        0.387     \\\\\n",
       "\\textbf{X2}    &       0.0483  &        0.057     &     0.853  &         0.404        &       -0.070    &        0.166     \\\\\n",
       "\\textbf{X3}    &       1.3060  &        0.164     &     7.959  &         0.000        &        0.964    &        1.648     \\\\\n",
       "\\textbf{X4}    &       0.5198  &        0.132     &     3.940  &         0.001        &        0.245    &        0.795     \\\\\n",
       "\\textbf{const} &    -124.3818  &        9.941     &   -12.512  &         0.000        &     -145.119    &     -103.645     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.256 & \\textbf{  Durbin-Watson:     } &    1.148  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.196 & \\textbf{  Jarque-Bera (JB):  } &    1.419  \\\\\n",
       "\\textbf{Skew:}          &  0.139 & \\textbf{  Prob(JB):          } &    0.492  \\\\\n",
       "\\textbf{Kurtosis:}      &  1.867 & \\textbf{  Cond. No.          } & 2.47e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.47e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.963\n",
       "Model:                            OLS   Adj. R-squared:                  0.955\n",
       "Method:                 Least Squares   F-statistic:                     129.7\n",
       "Date:                Fri, 04 Oct 2024   Prob (F-statistic):           5.26e-14\n",
       "Time:                        22:36:37   Log-Likelihood:                -67.951\n",
       "No. Observations:                  25   AIC:                             145.9\n",
       "Df Residuals:                      20   BIC:                             152.0\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
       "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
       "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
       "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
       "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
       "==============================================================================\n",
       "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
       "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
       "Skew:                           0.139   Prob(JB):                        0.492\n",
       "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = 'Y'\n",
    "modelo = sm.OLS(df[outcome], df[['X1', 'X2', 'X3', 'X4']].assign(const=1))\n",
    "resultado_1 = modelo.fit()\n",
    "resultado_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.963\n",
      "Model:                            OLS   Adj. R-squared:                  0.955\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Fri, 04 Oct 2024   Prob (F-statistic):           5.26e-14\n",
      "Time:                        22:36:37   Log-Likelihood:                -67.951\n",
      "No. Observations:                  25   AIC:                             145.9\n",
      "Df Residuals:                      20   BIC:                             152.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
      "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
      "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
      "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
      "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
      "==============================================================================\n",
      "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
      "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
      "Skew:                           0.139   Prob(JB):                        0.492\n",
      "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(resultado_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de los coeficientes de regresión**\n",
    "\n",
    "- **Variable x1:**\n",
    "Por cada aumento de una unidad en `x1`, la habilidad laboral aumenta en 0.2957. Este coeficiente es estadísticamente significativo, lo que indica una relación positiva con la habilidad laboral.\n",
    "\n",
    "- **Variable x2:**\n",
    "El coeficiente de `x2` es 0.0483, con un valor p de 0.404. Esto sugiere que `x2` no tiene una relación relevante con la habilidad laboral. Por lo tanto, se puede considerar eliminar esta variable en análisis posteriores.\n",
    "\n",
    "- **Variable x3:**\n",
    "`x3` muestra la relación más fuerte con la habilidad laboral, con un coeficiente de 1.3060 y un valor p de 0.000. Esto sugiere que es la variable con mayor relación positiva y estadísticamente significativa respecto a la habilidad laboral.\n",
    "\n",
    "- **Variable x4:**\n",
    "El coeficiente de `x4` es 0.5198, también indicando una relación positiva con la habilidad laboral. El valor p asociado es 0.001, lo que demuestra que esta variable tiene una relación estadísticamente significativa con la habilidad laboral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1: por cada aumento de una unidad en x1, la habilidad laboral aumenta 0.2957 y asi mismo es estadisticamente significativo, para x2 tiene un coheficiente pequeño de 0.0483 con un  p valor de 0.404  lo que sugiere que el x2 no tiene una relacion relevante con la habilidad laboral y se puede sugerir para posteriores analisis eliminar la variable,  coefciente x4 es de 0.5198 lo que tambien indica una relacion positiva y con un un valor p del 0.001, el cual es significativo lo que indica una fuerte relacion con la habilidad laboral, y por ultimo x3 muestra la relacion mas fuerte positiva 1.3060 y un valor p 0.000 significativo el cual sugiere que es la variable con mayor relacion positiva frente a la habilidad laboral habilidad laboral \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 2**\n",
    "\n",
    "Identifique observaciones que puedan considerarse problemáticas (datos atípicos, puntos de balanceo e influyentes) y analice si debe eliminarlas de su conjunto de datos o no, justifique. Repita la construcción del modelode regresión si eliminó observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea un modelo de regresión lineal  usando 'outcome' \n",
    "#como variable dependiente y las variables independientes X1, X2, X3 y X4.\n",
    "modelo=sm.OLS(df[outcome],df[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado=modelo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.963\n",
      "Model:                            OLS   Adj. R-squared:                  0.955\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Fri, 04 Oct 2024   Prob (F-statistic):           5.26e-14\n",
      "Time:                        22:36:37   Log-Likelihood:                -67.951\n",
      "No. Observations:                  25   AIC:                             145.9\n",
      "Df Residuals:                      20   BIC:                             152.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
      "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
      "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
      "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
      "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
      "==============================================================================\n",
      "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
      "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
      "Skew:                           0.139   Prob(JB):                        0.492\n",
      "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(resultado.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "#Crea un objeto de influencia a partir de los resultados del modelo de regresión\n",
    "influencia=OLSInfluence(resultado)\n",
    "#Extrae los residuos estandarizados del modelo\n",
    "residuals=influencia.resid_studentized_internal\n",
    "# Localiza la fila del DataFrame con el residuo estandarizado más alto y bajo\n",
    "residuo_max=df.loc[residuals.idxmax(),:]\n",
    "residuo_min=df.loc[residuals.idxmin(),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor atipico minimo en la variable Y es 76 el valor atipico maximo en la variable Y es 100 \n"
     ]
    }
   ],
   "source": [
    "#Extrae el valor del resultado (Y) correspondiente al residuo mínimo y maximo\n",
    "outlier_min=residuo_min[outcome]\n",
    "outlier_maximo=residuo_max[outcome]\n",
    "\n",
    "df_filtrado = df[(df[outcome] == outlier_min) | (df[outcome] == outlier_maximo)]\n",
    "\n",
    "print(f'el valor atipico minimo en la variable Y es {outlier_min}\\\n",
    " el valor atipico maximo en la variable Y es {outlier_maximo} '      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores atípicos en la variable **Y**, con un mínimo de **76** y un máximo de **100**, indican la presencia de puntos extremos derivados de los residuos estandarizados del modelo. Estos puntos atípicos pueden tener un impacto significativo en el análisis de los datos y, por lo tanto, deben ser revisados cuidadosamente.\n",
    "\n",
    "En el dataframe, los valores atípicos identificados corresponden a las observaciones con índices **3** y **16**, con valores de **Y** de **76** y **100**, respectivamente. Es esencial evaluar el contexto de estos valores para determinar si representan un fenómeno válido o si podrían estar distorsionando el ajuste del modelo. En caso de que estos valores atípicos resulten de errores o de datos no confiables, sería conveniente considerarlos para su posible eliminación o tratamiento adecuado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "3    76  101  117   93   95\n",
       "16  100  104   83  100  102"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores atipicos filtrados en el data set \n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Valores influyentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene las distancias de Cook para cada observación\n",
    "cooks_d = influencia.cooks_distance[0]\n",
    "#Calcula el umbral para identificar puntos influyentes\n",
    "umbral=4/(len(df['Y'])-(df.shape[1]-1))\n",
    "# Identifica los índices de las observaciones \n",
    "# cuya distancia de Cook excede el umbral definido\n",
    "puntos_de_influencia=np.where(cooks_d>umbral)[0]\n",
    "#Extrae las distancias de Cook para esos puntos influyentes\n",
    "cooks_d[puntos_de_influencia]\n",
    "#Filtra el DataFrame para obtener las observaciones influyentes\n",
    "observaciones_influyentes = df.iloc[puntos_de_influencia]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los resultados obtenidos, se ha identificado un valor influyente de **0.191284**, ya que supera el umbral de **0.19047619**. Este valor corresponde a la observación con índice **15** en el dataframe, con los siguientes valores de las variables: \n",
    "\n",
    "- **Y**: 109\n",
    "- **X1**: 109\n",
    "- **X2**: 129\n",
    "- **X3**: 102\n",
    "- **X4**: 108\n",
    "\n",
    "La identificación de valores influyentes es crucial para garantizar la integridad del modelo, ya que estos puntos pueden alterar significativamente los resultados. En este caso, es recomendable considerar acciones como la eliminación de la observación si se determina que los datos son errores o provienen de información no confiable. Sin embargo, se debe realizar una evaluación adicional para confirmar si la observación refleja una situación válida o si representa un error de medición.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>129</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "15  109  109  129  102  108"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores influyentes filtrados data set\n",
    "observaciones_influyentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Punto de balanceo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_leverage = 2 * (df[['X1', 'X2', 'X3', 'X4']].shape[1] / len(df))\n",
    "leverage = influencia.hat_matrix_diag\n",
    "\n",
    "# Identificar los puntos de balanceo\n",
    "puntos_de_balanceo = np.where(leverage > umbral_leverage)[0]\n",
    "\n",
    "# Filtrar el DataFrame para obtener las observaciones de balanceo\n",
    "observaciones_balanceo = df.iloc[puntos_de_balanceo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos de balanceo son observaciones en las variables **X1**, **X2**, **X3** o **X4** que tienen el potencial de influir significativamente en los resultados de un modelo. La identificación de estos puntos es esencial para asegurar que el modelo no esté sesgado por un conjunto reducido de datos que pueda distorsionar las conclusiones generales.\n",
    "\n",
    "El procedimiento realizado para identificar estos valores tiene como objetivo verificar que no existan puntos de balanceo que estén ejerciendo una influencia desproporcionada sobre el modelo. Revisar estos valores ayuda a garantizar que los resultados sean representativos del conjunto de datos en su totalidad y que no estén dominados por observaciones particulares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>97</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>120</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y   X1  X2  X3   X4\n",
       "1  80   62  97  99  100\n",
       "6  58  120  77  80   74"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observaciones_balanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Análisis Comparativo de Modelos: Eliminando datos atipicos, influyentes y balanceo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desarrollaron cinco modelos de regresión lineal para analizar el conjunto de datos, considerando tanto la inclusión como la exclusión de valores atípicos, influyentes y de balanceo. En la primera fase, se construyó un modelo utilizando **todos los datos disponibles**, lo que permitió captar la tendencia general y las relaciones entre las variables.\n",
    "\n",
    "1. **Modelo con todos los datos (modelo_all_variables)**\n",
    "2. **Modelo con datos atípicos eliminados (Modelo_sin_atipicos)**.\n",
    "3. **Modelo con datos influyentes eliminados (Modelo_sin_influyentes)**\n",
    "3. **Modelo con datos balanceo eliminados (Modelo_sin_balanceo)**.\n",
    "3. **Modelo con todos los datos atípicos, influyentes y de balanceo eliminados (Sin_all_errores )**.\n",
    "\n",
    "Esta metodología de comparación permitió evaluar la robustez de los enfoques y analizar cómo la presencia de datos extremos afecta la interpretación de los resultados. Los diferentes enfoques ofrecieron una perspectiva más completa sobre cómo los valores extremos pueden influir en las predicciones del modelo, proporcionando una base sólida para tomar decisiones sobre el manejo de estos puntos en análisis futuros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar=df.copy()\n",
    "# se eliminan los valores atipicos encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar.drop(index=[3, 16], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_atipicos=sm.OLS(df_eliminar[outcome],df_eliminar[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_2=modelo_atipicos.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_2=df.copy()\n",
    "# se eliminan los valores influyentes encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_2.drop(index=[15], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_influyentes=sm.OLS(df_eliminar_2[outcome],df_eliminar_2[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_3=modelo_influyentes.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_4=df.copy()\n",
    "# se eliminan los valores de balanceo encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_4.drop(index=[1,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_balanceo=sm.OLS(df_eliminar_4[outcome],df_eliminar_4[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_4=modelo_balanceo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_5=df.copy()\n",
    "# se eliminan todos los  encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_5.drop(index=[3,16,15,1,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_balanceo=sm.OLS(df_eliminar_5[outcome],df_eliminar_5[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_5=modelo_balanceo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cuadro resumen de los criterios de los modelos** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo_all_variables</th>\n",
       "      <th>Modelo_sin_atipicos</th>\n",
       "      <th>Modelo_sin_influyentes</th>\n",
       "      <th>Modelo_sin_balanceo</th>\n",
       "      <th>Sin_all_arrores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.962892</td>\n",
       "      <td>0.971449</td>\n",
       "      <td>0.966514</td>\n",
       "      <td>0.956046</td>\n",
       "      <td>0.969393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 ajus</th>\n",
       "      <td>0.955470</td>\n",
       "      <td>0.965105</td>\n",
       "      <td>0.959464</td>\n",
       "      <td>0.946279</td>\n",
       "      <td>0.961231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f stad</th>\n",
       "      <td>129.741157</td>\n",
       "      <td>153.114579</td>\n",
       "      <td>137.099986</td>\n",
       "      <td>97.880728</td>\n",
       "      <td>118.769310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>145.901138</td>\n",
       "      <td>130.072863</td>\n",
       "      <td>138.187575</td>\n",
       "      <td>136.940795</td>\n",
       "      <td>114.350413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bic</th>\n",
       "      <td>151.995517</td>\n",
       "      <td>135.750334</td>\n",
       "      <td>144.077845</td>\n",
       "      <td>142.618266</td>\n",
       "      <td>119.329074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Modelo_all_variables  Modelo_sin_atipicos  Modelo_sin_influyentes  \\\n",
       "r2                   0.962892             0.971449                0.966514   \n",
       "r2 ajus              0.955470             0.965105                0.959464   \n",
       "f stad             129.741157           153.114579              137.099986   \n",
       "AIC                145.901138           130.072863              138.187575   \n",
       "Bic                151.995517           135.750334              144.077845   \n",
       "\n",
       "         Modelo_sin_balanceo  Sin_all_arrores  \n",
       "r2                  0.956046         0.969393  \n",
       "r2 ajus             0.946279         0.961231  \n",
       "f stad             97.880728       118.769310  \n",
       "AIC               136.940795       114.350413  \n",
       "Bic               142.618266       119.329074  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadro = {\n",
    "    'Modelo_all_variables': {'r2': resultado_1.rsquared, 'r2 ajus':resultado_1.rsquared_adj\n",
    "    ,'f stad':resultado_1.fvalue,'AIC':resultado_1.aic,'Bic': resultado_1.bic},\n",
    "    'Modelo_sin_atipicos': {'r2': resultado_2.rsquared, 'r2 ajus':resultado_2.rsquared_adj\n",
    "    ,'f stad':resultado_2.fvalue,'AIC':resultado_2.aic,\n",
    "    'Bic': resultado_2.bic,\n",
    "    }, 'Modelo_sin_influyentes': {'r2': resultado_3.rsquared, 'r2 ajus':resultado_3.rsquared_adj\n",
    "      ,'f stad':resultado_3.fvalue,'AIC':resultado_3.aic,\n",
    "    'Bic': resultado_3.bic,\n",
    "    }, 'Modelo_sin_balanceo': {'r2': resultado_4.rsquared, 'r2 ajus':resultado_4.rsquared_adj\n",
    "      ,'f stad':resultado_4.fvalue,'AIC':resultado_4.aic, 'Bic': resultado_4.bic,\n",
    "      }, 'Sin_all_arrores': {'r2': resultado_5.rsquared, 'r2 ajus':resultado_5.rsquared_adj\n",
    "      ,'f stad':resultado_5.fvalue,'AIC':resultado_5.aic, 'Bic': resultado_5.bic,     \n",
    "    \n",
    "}}\n",
    "resumen=pd.DataFrame(cuadro)\n",
    "resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presentan las métricas clave para comparar los diferentes modelos de regresión lineal según las modificaciones realizadas en los datos (eliminación de datos atípicos, influyentes y de balanceo):\n",
    "\n",
    "- **R²**: El modelo sin datos atípicos muestra el mejor ajuste, con un valor de **0.971449**, lo que indica que este modelo explica la mayor proporción de la varianza en la variable dependiente.\n",
    "  \n",
    "- **R² Ajustado**: De manera similar, el modelo sin datos atípicos tiene el mejor ajuste ajustado con **0.965105**, lo que confirma que sigue siendo el modelo más robusto incluso al ajustar por el número de predictores.\n",
    "\n",
    "- **F-Statistic**: El modelo sin datos atípicos también exhibe una mayor significancia estadística con un valor de **153.114**, lo que sugiere que explica significativamente más de la variabilidad en la variable dependiente en comparación con el error.\n",
    "\n",
    "- **AIC**: El modelo sin datos atípicos, influyentes y de balanceo tiene el AIC más bajo, con un valor de **114.350413**, indicando que este modelo penaliza menos la complejidad y es más eficiente en términos de ajuste y parsimonia.\n",
    "\n",
    "- **BIC**: De manera consistente, el modelo sin datos atípicos, influyentes y de balanceo tiene el BIC más bajo, con **119.329074**, favoreciendo modelos más simples y penalizando la complejidad excesiva.\n",
    "\n",
    "En conclusión, si se busca un modelo más **simple e interpretativo**, optar por el modelo que excluye datos atípicos, influyentes y de balanceo parece ser la mejor opción, ya que ofrece un buen ajuste con menor riesgo de sobreajuste. Sin embargo, si el objetivo principal es **maximizar la precisión predictiva** y preservar la interpretación de los datos originales, mantener un modelo con todos los datos puede ser preferible. La falta de cambios significativos en criterios como el **R²** sugiere que la eliminación de estos datos extremos no es absolutamente necesaria para todos los casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 3**\n",
    "\n",
    "Realice la prueba de significancia del modelo, interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se saca el p valor del modelo\n",
    "p_value_modelo = resultado_1.f_pvalue\n",
    "\n",
    "# Obtener coeficientes y valores p\n",
    "coeficientes = resultado_1.params\n",
    "valores_p = resultado_1.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Análisis** \n",
    "\n",
    "Se evaluó la significancia del modelo utilizando el valor **p** y los coeficientes de las variables independientes **X1**, **X2**, **X3** y **X4**. Los resultados muestran lo siguiente:\n",
    "\n",
    "- **Valor p del modelo**: El valor **p** obtenido es de **5.26×10⁻¹⁴**, que está muy por debajo del umbral común de **0.05**. Esto indica que el modelo es significativo en su conjunto, sugiriendo que las variables **X** están explicando variabilidad en **Y** de manera estadísticamente significativa.\n",
    "  \n",
    "- **R²**: El coeficiente de determinación **R²** es de **96.29%**, lo que sugiere que el modelo ajusta bien a los datos, explicando la mayor parte de la variabilidad de la variable dependiente **Y**.\n",
    "\n",
    "Las variables se evaluaron en función de su valor **p**, donde un valor **p** menor a **0.05** se considera indicativo de significancia:\n",
    "\n",
    "- **X1**: **0.000** (significativo)\n",
    "- **X2**: **0.404** (no significativo)\n",
    "- **X3**: **0.000** (significativo)\n",
    "- **X4**: **0.001** (significativo)\n",
    "\n",
    "Esto sugiere que **X1**, **X3** y **X4** son las variables más relevantes en el modelo, mientras que **X2** no tiene un efecto significativo sobre la habilidad laboral, dado su valor **p** mayor a **0.05**.\n",
    "\n",
    "Los coeficientes estimados para las variables son:\n",
    "\n",
    "- **X1**: **0.2957**\n",
    "- **X2**: **0.0483**\n",
    "- **X3**: **1.3060**\n",
    "- **X4**: **0.5198**\n",
    "\n",
    "Todos los coeficientes son positivos, lo que indica que las variables tienen una relación positiva con la habilidad laboral. Sin embargo, **X3** tiene el coeficiente más alto, lo que sugiere que es la variable con el mayor efecto sobre la habilidad laboral.\n",
    "\n",
    "El análisis muestra que **X1**, **X3** y **X4** son variables significativas para explicar la habilidad laboral, siendo **X3** la que tiene el mayor impacto. Dado que **X2** no es significativa (valor **p** de **0.404**), se podría considerar la posibilidad de eliminarla del modelo para simplificarlo sin perder capacidad explicativa. Focalizarse en mejorar o entender mejor **X1**, **X3** y **X4** podría tener un impacto considerable en la habilidad laboral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 4**\n",
    "\n",
    "Obtener el coeficiente de determinación y el coeficiente de determinación ajustado. Interprete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretación de R2**\n",
    "\n",
    "el valor de determinacion alto suguiere, ue una gran proporción de la variabilidad en la variable dependiente puede ser explicada por las variables independientes del modelo. en este caso por **0.963**, indica que el 96% de la variabilidad se puede explicar por el modelo.\n",
    "\n",
    "**coeficiente de determinación ajustado**\n",
    "\n",
    "ste valor es más confiable en comparación con R2, penaliza el modelo por incluir predictores que no son útiles. Esto ayuda a evitar el sobreajuste.entre mayor el R2 ajustado, la medida ofrece una medida mas confiable de la calidad del ajuste en relación con la complejidad del modelo. para este caso el r2 ajustado es de **0.955**  e la variabilidad de la variable dependiente es explicada por las variables independientes en el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 5**\n",
    "\n",
    "Analice si hay problemas de multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variable       VIF\n",
      "0       X1  1.138043\n",
      "1       X2  1.369512\n",
      "2       X3  3.016549\n",
      "3       X4  2.834776\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tienes un DataFrame llamado df con tus variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "# Estandarizar las variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[variables])\n",
    "\n",
    "# Calcular el VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = variables\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se realiza analisis de multicolinealidad mediante el calculo VIF, enterminos generales las variables cuentan con valores VIF aceptables, siendo todos menores a 5, para la variable x3 podria requerir una revision adicional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1        X2        X3        X4\n",
      "X1  1.000000  0.102269  0.180769  0.326663\n",
      "X2  0.102269  1.000000  0.519045  0.396710\n",
      "X3  0.180769  0.519045  1.000000  0.782038\n",
      "X4  0.326663  0.396710  0.782038  1.000000\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df[variables].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se realiza un grafico de analisis de correlacion de las variables en el que x3 y x4 tienen una relacion alta con 0.728 lo que sugiere una colinealidad importante entre las dos variables. el cual puede estar contribuyendo al VIF elevado del X3.\n",
    "\n",
    "Aunque la matriz de correlación no muestra correlaciones extremadamente altas en todas las variables, sin embargo las variables x3 y x4 se observa una correlacion significativa por lo que  el uso de PCA sigue siendo relevante para simplificar la estructura de los datos y mejorar la efectividad de los análisis posteriores. \n",
    "Dado que los componentes principales son combinaciones lineales de las variables originales, eliminan la redundancia y la colinealidad, lo que puede ayudar a que tu modelo sea más robusto y estable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "df_pca = pd.DataFrame(X_pca)\n",
    "\n",
    "df_pca.columns = ['PC'+str(i) for i in range(df_pca.shape[1])]\n",
    "\n",
    "df_pca['Y']=df[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianza_explicada = pca.explained_variance_ratio_\n",
    "\n",
    "# Calcular la varianza acumulada\n",
    "varianza_acumulada = varianza_explicada.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuevas variables reducidas\n",
    "# ya que x3 y x4 tenian una correlacion bastante alta por lo que no es necesario tener dos variables \n",
    "# con el mismo comportamiento \n",
    "\n",
    "df['pca_1']=X_pca[:,0]\n",
    "df['pca_2']=X_pca[:,1]\n",
    "df['pca_3']=X_pca[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se realiza el analisis de componentes PCA para reducir la dimensionalidad, se decidio tener tres componentes principales el cual asegura el 95% de la variabilidad total. el primer componen explica el 56% de la varianza, el segundo 23% y por ultimo 16%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              pca_1         pca_2         pca_3\n",
      "pca_1  1.000000e+00  2.225037e-16  7.555501e-17\n",
      "pca_2  2.225037e-16  1.000000e+00 -1.051476e-16\n",
      "pca_3  7.555501e-17 -1.051476e-16  1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = df[['pca_1','pca_2','pca_3']].corr()\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se vuelve hacer el analisis de correlacion de las nuevas variables reducidas pca_1, pca_2 y muestra una correlacion practicamente de 0, lo que indica que las dos componentes principales no estan correlacionados, esto es beneficioso para los modelos de machine learning ya que asumen que las caracteristicas son independientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 6**\n",
    "Realice una selección e variables por el método que prefiera, tome decisiones, explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Optimización del Modelo**\n",
    "\n",
    "El objetivo principal es identificar el mejor modelo posible mediante un proceso de **selección de variables**, equilibrando la complejidad del modelo y su capacidad de ajuste a los datos. Para ello, se ha utilizado el criterio de información de Akaike (**AIC**), que penaliza los modelos más complejos y favorece aquellos que logran un equilibrio adecuado entre ajuste y simplicidad.\n",
    "\n",
    "El uso del **AIC** permite determinar qué variables tienen un impacto significativo en los resultados del modelo predictivo. A través de este enfoque, se busca identificar las variables que contribuyen de manera relevante al ajuste del modelo, eliminando aquellas que no mejoran la precisión predictiva o que introducen complejidad innecesaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: X1, X2, X3, X4\n",
      "Start: score=222.25, constant\n",
      "Step: score=183.42, add X3\n",
      "Step: score=158.67, add X1\n",
      "Step: score=146.79, add X4\n",
      "Step: score=146.79, unchanged None\n",
      "\n",
      "Intercept: -124.2000165715195\n",
      "Coefficients:\n",
      " X3: 1.357\n",
      " X1: 0.2963\n",
      " X4: 0.5174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#  variable dependiente o a predecir\n",
    "y = df[outcome]\n",
    "\n",
    "# variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "\n",
    "# se crea una funcion donde esta almacenado el modelo de regresion lineal \n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[variables], y)  # Ajustar el modelo con las variables X1, X2, X3, X4\n",
    "    return model\n",
    "\n",
    "# se Calcula el AIC usando las predicciones del modelo\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(y, [y.mean()] * len(y), model, df=1)\n",
    "    return AIC_score(y, model.predict(df[variables]), model)\n",
    "\n",
    " \n",
    "# Aquí se pasan las variables específicas para la selección\n",
    "# penalizando la complejidad del modelo para evitar el sobreajuste\n",
    "# utilizando la funcion stepwise_selection de la libreria dmba se seleciona las mejores varuables \n",
    "best_model, best_variables = stepwise_selection(variables, train_model, score_model, \n",
    "                                                verbose=True)\n",
    "\n",
    "# Imprimir resultados\n",
    "print()\n",
    "print(f'Intercept: {best_model.intercept_}')\n",
    "print('Coefficients:')\n",
    "for name, coef in zip(best_variables, best_model.coef_):\n",
    "    print(f' {name}: {round(coef,4)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **modelo final** incluye las variables **X1**, **X3** y **X4**, ya que la inclusión de **X2** no mejoró significativamente el ajuste del modelo. Este enfoque optimiza tanto el ajuste a los datos como la complejidad del modelo, priorizando las variables que tienen un impacto significativo.\n",
    "\n",
    "Un **modelo más simple** que solo incluye las variables relevantes no solo facilita la interpretación de los resultados, sino que también reduce el riesgo de **sobreajuste**. El sobreajuste ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento, lo que compromete su capacidad de generalización a nuevos datos. Al excluir variables innecesarias, se mejora la robustez del modelo, haciéndolo más confiable y eficiente en situaciones predictivas.\n",
    "\n",
    "El enfoque final, que excluye la variable **X2**, optimiza el balance entre la precisión predictiva y la simplicidad, asegurando un modelo más interpretativo y con menor riesgo de sobreajuste. Este resultado sugiere que enfocarse en las variables **X1**, **X3** y **X4** es suficiente para lograr un buen rendimiento sin añadir complejidad innecesaria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>pca_1</th>\n",
       "      <th>pca_2</th>\n",
       "      <th>pca_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>110</td>\n",
       "      <td>100</td>\n",
       "      <td>87</td>\n",
       "      <td>0.644822</td>\n",
       "      <td>-0.891515</td>\n",
       "      <td>0.233856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>97</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "      <td>0.665878</td>\n",
       "      <td>-1.578005</td>\n",
       "      <td>-1.250294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y  X1   X2   X3   X4     pca_1     pca_2     pca_3\n",
       "0  88  86  110  100   87  0.644822 -0.891515  0.233856\n",
       "1  80  62   97   99  100  0.665878 -1.578005 -1.250294"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 7**\n",
    "Realice una predicción utilizando el modelo seleccionado, interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome='Y'\n",
    "modelo_seleccion=sm.OLS(df[outcome],df[['X1','X3','X4']].assign(const=1))\n",
    "resultado_variables=modelo_seleccion.fit()\n",
    "#resultado_variables.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome='Y'\n",
    "modelo_con_pca=sm.OLS(df[outcome],df[['pca_1','pca_2','pca_3']].assign(const=1))\n",
    "resultado_pca=modelo_con_pca.fit()\n",
    "#resultado_variables.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo de seleccion de variables</th>\n",
       "      <th>modelo_pca</th>\n",
       "      <th>borrando datos all_atipicos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.961542</td>\n",
       "      <td>0.949221</td>\n",
       "      <td>0.969393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 ajus</th>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.941967</td>\n",
       "      <td>0.961231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f stad</th>\n",
       "      <td>175.017647</td>\n",
       "      <td>130.852399</td>\n",
       "      <td>118.769310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>144.794242</td>\n",
       "      <td>151.742244</td>\n",
       "      <td>114.350413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bic</th>\n",
       "      <td>149.669745</td>\n",
       "      <td>156.617748</td>\n",
       "      <td>119.329074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         modelo de seleccion de variables  modelo_pca  \\\n",
       "r2                               0.961542    0.949221   \n",
       "r2 ajus                          0.956048    0.941967   \n",
       "f stad                         175.017647  130.852399   \n",
       "AIC                            144.794242  151.742244   \n",
       "Bic                            149.669745  156.617748   \n",
       "\n",
       "         borrando datos all_atipicos  \n",
       "r2                          0.969393  \n",
       "r2 ajus                     0.961231  \n",
       "f stad                    118.769310  \n",
       "AIC                       114.350413  \n",
       "Bic                       119.329074  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadro = {\n",
    "    'modelo de seleccion de variables': {'r2': resultado_variables.rsquared, 'r2 ajus':resultado_variables.rsquared_adj\n",
    "    ,'f stad':resultado_variables.fvalue,'AIC':resultado_variables.aic,'Bic': resultado_variables.bic},\n",
    "    'modelo_pca': {'r2': resultado_pca.rsquared, 'r2 ajus':resultado_pca.rsquared_adj\n",
    "    ,'f stad':resultado_pca.fvalue,'AIC':resultado_pca.aic,'Bic': resultado_pca.bic},\n",
    "    'borrando datos all_atipicos': {'r2': resultado_5.rsquared, 'r2 ajus':resultado_5.rsquared_adj\n",
    "    ,'f stad':resultado_5.fvalue,'AIC':resultado_5.aic,'Bic': resultado_5.bic},\n",
    "        \n",
    "    \n",
    "}\n",
    "resumen=pd.DataFrame(cuadro)\n",
    "resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **modelo que elimina datos atípicos** es efectivo en términos de ajuste y generalización. Sin embargo, se eliminaron datos sin una comprensión clara de su presencia, por lo que no se recomienda sin un análisis contextual adecuado.\n",
    "\n",
    "El **modelo de reducción de variables con criterio AIC** elimina variables irrelevantes, reduciendo el **sobreajuste** y mejorando el rendimiento en nuevos datos. Además, disminuye el tiempo de entrenamiento, facilitando su implementación.\n",
    "\n",
    "El **modelo PCA** muestra un **R² de 0.949221** y un **R² ajustado de 0.941967**, indicando un buen ajuste, pero inferior al modelo de selección de variables y con limitaciones en interpretación.\n",
    "\n",
    "Se recomienda el **modelo de selección de variables**, ya que facilita la interpretación, mejora la eficiencia y permite comprender mejor la influencia de cada variable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
