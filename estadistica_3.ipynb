{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#00693E; color:white; padding:20px; border-radius:10px; font-family:sans-serif; text-align:left;\">\n",
    "    <h1 style=\"margin-bottom:10px; font-weight:bold;\">Universidad de Antioquia</h1>\n",
    "    <h2 style=\"margin-bottom:15px; font-weight:bold;\">Especialización en Analítica y Ciencia de Datos</h2>\n",
    "    <h3 style=\"font-weight:normal; margin-bottom:20px;\">Estadística y Análisis Exploratorio</h3>\n",
    "    <p style=\"font-size:20px; font-weight:bold; margin-bottom:10px;\">Trabajo 3</p>\n",
    "    <p style=\"font-size:16px; margin-bottom:5px;\"><strong>Profesor:</strong> Javier Lozano</p>\n",
    "    <p style=\"font-size:16px;\"><strong>Integrantes:</strong> Andres Fonseca y Felipe Quinto</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dmba import stepwise_selection\n",
    "from dmba import AIC_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='laboral.csv'\n",
    "df=pd.read_csv(url,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Contexto**\n",
    "\n",
    "El jefe de personal de una agencia gubernamental administró cuatro pruebas de aptitud a cada uno de los 25 aspirantes a cargos administrativos en la agencia. Para el propósito del estudio, se aceptaron a todos los aspirantes para 25 posiciones independientemente de sus puntajes en las pruebas. Después de un período de prueba, cada aspirante fue evaluado en su habilidad de trabajo. El puntaje obtenido relativo a la habilidad laboral (Y) y los puntajes en las cuatro pruebas (X1, X2, X3, X4) están consignados en el archivo `laboral.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 1**\n",
    "\n",
    "Emplee el análisis de regresión lineal múltiple para obtener una ecuación de regresión estimada que sirva para pronosticar la habilidad laboral, dadas las demás variables (Xi)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 + \\beta_4 X_4 + \\varepsilon\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $Y$ es la variable dependiente (habilidad laboral).\n",
    "- $X_1, X_2, X_3, X_4$ son las variables predictoras (puntajes de las pruebas).\n",
    "- $\\beta_0$ es la ordenada al origen (intercepto).\n",
    "- $\\beta_1, \\beta_2, \\beta_3, \\beta_4$ son los coeficientes de regresión asociados a cada predictor.\n",
    "- $\\varepsilon$ es el término de error.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   129.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 02 Oct 2024</td> <th>  Prob (F-statistic):</th> <td>5.26e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:31:51</td>     <th>  Log-Likelihood:    </th> <td> -67.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    25</td>      <th>  AIC:               </th> <td>   145.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   152.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    0.2957</td> <td>    0.044</td> <td>    6.725</td> <td> 0.000</td> <td>    0.204</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    0.0483</td> <td>    0.057</td> <td>    0.853</td> <td> 0.404</td> <td>   -0.070</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td>    1.3060</td> <td>    0.164</td> <td>    7.959</td> <td> 0.000</td> <td>    0.964</td> <td>    1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>    <td>    0.5198</td> <td>    0.132</td> <td>    3.940</td> <td> 0.001</td> <td>    0.245</td> <td>    0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -124.3818</td> <td>    9.941</td> <td>  -12.512</td> <td> 0.000</td> <td> -145.119</td> <td> -103.645</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.256</td> <th>  Durbin-Watson:     </th> <td>   1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.196</td> <th>  Jarque-Bera (JB):  </th> <td>   1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.139</td> <th>  Prob(JB):          </th> <td>   0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.867</td> <th>  Cond. No.          </th> <td>2.47e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.47e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        Y         & \\textbf{  R-squared:         } &     0.963   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.955   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     129.7   \\\\\n",
       "\\textbf{Date:}             & Wed, 02 Oct 2024 & \\textbf{  Prob (F-statistic):} &  5.26e-14   \\\\\n",
       "\\textbf{Time:}             &     23:31:51     & \\textbf{  Log-Likelihood:    } &   -67.951   \\\\\n",
       "\\textbf{No. Observations:} &          25      & \\textbf{  AIC:               } &     145.9   \\\\\n",
       "\\textbf{Df Residuals:}     &          20      & \\textbf{  BIC:               } &     152.0   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{X1}    &       0.2957  &        0.044     &     6.725  &         0.000        &        0.204    &        0.387     \\\\\n",
       "\\textbf{X2}    &       0.0483  &        0.057     &     0.853  &         0.404        &       -0.070    &        0.166     \\\\\n",
       "\\textbf{X3}    &       1.3060  &        0.164     &     7.959  &         0.000        &        0.964    &        1.648     \\\\\n",
       "\\textbf{X4}    &       0.5198  &        0.132     &     3.940  &         0.001        &        0.245    &        0.795     \\\\\n",
       "\\textbf{const} &    -124.3818  &        9.941     &   -12.512  &         0.000        &     -145.119    &     -103.645     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.256 & \\textbf{  Durbin-Watson:     } &    1.148  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.196 & \\textbf{  Jarque-Bera (JB):  } &    1.419  \\\\\n",
       "\\textbf{Skew:}          &  0.139 & \\textbf{  Prob(JB):          } &    0.492  \\\\\n",
       "\\textbf{Kurtosis:}      &  1.867 & \\textbf{  Cond. No.          } & 2.47e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.47e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.963\n",
       "Model:                            OLS   Adj. R-squared:                  0.955\n",
       "Method:                 Least Squares   F-statistic:                     129.7\n",
       "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           5.26e-14\n",
       "Time:                        23:31:51   Log-Likelihood:                -67.951\n",
       "No. Observations:                  25   AIC:                             145.9\n",
       "Df Residuals:                      20   BIC:                             152.0\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
       "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
       "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
       "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
       "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
       "==============================================================================\n",
       "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
       "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
       "Skew:                           0.139   Prob(JB):                        0.492\n",
       "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome = 'Y'\n",
    "modelo = sm.OLS(df[outcome], df[['X1', 'X2', 'X3', 'X4']].assign(const=1))\n",
    "resultado_1 = modelo.fit()\n",
    "resultado_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.963\n",
      "Model:                            OLS   Adj. R-squared:                  0.955\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           5.26e-14\n",
      "Time:                        23:31:51   Log-Likelihood:                -67.951\n",
      "No. Observations:                  25   AIC:                             145.9\n",
      "Df Residuals:                      20   BIC:                             152.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
      "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
      "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
      "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
      "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
      "==============================================================================\n",
      "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
      "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
      "Skew:                           0.139   Prob(JB):                        0.492\n",
      "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(resultado_1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Análisis de los coeficientes de regresión**\n",
    "\n",
    "- **Variable x1:**\n",
    "Por cada aumento de una unidad en `x1`, la habilidad laboral aumenta en 0.2957. Este coeficiente es estadísticamente significativo, lo que indica una relación positiva con la habilidad laboral.\n",
    "\n",
    "- **Variable x2:**\n",
    "El coeficiente de `x2` es 0.0483, con un valor p de 0.404. Esto sugiere que `x2` no tiene una relación relevante con la habilidad laboral. Por lo tanto, se puede considerar eliminar esta variable en análisis posteriores.\n",
    "\n",
    "- **Variable x3:**\n",
    "`x3` muestra la relación más fuerte con la habilidad laboral, con un coeficiente de 1.3060 y un valor p de 0.000. Esto sugiere que es la variable con mayor relación positiva y estadísticamente significativa respecto a la habilidad laboral.\n",
    "\n",
    "- **Variable x4:**\n",
    "El coeficiente de `x4` es 0.5198, también indicando una relación positiva con la habilidad laboral. El valor p asociado es 0.001, lo que demuestra que esta variable tiene una relación estadísticamente significativa con la habilidad laboral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1: por cada aumento de una unidad en x1, la habilidad laboral aumenta 0.2957 y asi mismo es estadisticamente significativo, para x2 tiene un coheficiente pequeño de 0.0483 con un  p valor de 0.404  lo que sugiere que el x2 no tiene una relacion relevante con la habilidad laboral y se puede sugerir para posteriores analisis eliminar la variable,  coefciente x4 es de 0.5198 lo que tambien indica una relacion positiva y con un un valor p del 0.001, el cual es significativo lo que indica una fuerte relacion con la habilidad laboral, y por ultimo x3 muestra la relacion mas fuerte positiva 1.3060 y un valor p 0.000 significativo el cual sugiere que es la variable con mayor relacion positiva frente a la habilidad laboral habilidad laboral \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 2**\n",
    "\n",
    "Identifique observaciones que puedan considerarse problemáticas (datos atípicos, puntos de balanceo e influyentes) y analice si debe eliminarlas de su conjunto de datos o no, justifique. Repita la construcción del modelode regresión si eliminó observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Outliers**\n",
    "Residuos estandarizados:\n",
    "$$\n",
    "r_i = \\frac{e_i}{\\hat{\\sigma}(e_i)}\n",
    "$$\n",
    "\n",
    "#### **Puntos de influencia**\n",
    "Distancia de Cook:\n",
    "$$\n",
    "D_i = \\frac{r_i^2}{k} \\cdot \\frac{h_{ii}}{(1 - h_{ii})^2}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $h_{ii}$ es el valor de apalancamiento para la observación $i$.\n",
    "- $k$ es el número de parámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea un modelo de regresión lineal  usando 'outcome' \n",
    "#como variable dependiente y las variables independientes X1, X2, X3 y X4.\n",
    "modelo=sm.OLS(df[outcome],df[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado=modelo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.963\n",
      "Model:                            OLS   Adj. R-squared:                  0.955\n",
      "Method:                 Least Squares   F-statistic:                     129.7\n",
      "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           5.26e-14\n",
      "Time:                        23:31:51   Log-Likelihood:                -67.951\n",
      "No. Observations:                  25   AIC:                             145.9\n",
      "Df Residuals:                      20   BIC:                             152.0\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
      "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
      "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
      "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
      "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
      "==============================================================================\n",
      "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
      "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
      "Skew:                           0.139   Prob(JB):                        0.492\n",
      "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(resultado.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **valores atipicos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "#Crea un objeto de influencia a partir de los resultados del modelo de regresión\n",
    "influencia=OLSInfluence(resultado)\n",
    "#Extrae los residuos estandarizados del modelo\n",
    "residuals=influencia.resid_studentized_internal\n",
    "# Localiza la fila del DataFrame con el residuo estandarizado más alto y bajo\n",
    "residuo_max=df.loc[residuals.idxmax(),:]\n",
    "residuo_min=df.loc[residuals.idxmin(),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor atipico minimo en la variable Y es 76 el valor atipico maximo en la variable Y es 100 \n"
     ]
    }
   ],
   "source": [
    "#Extrae el valor del resultado (Y) correspondiente al residuo mínimo y maximo\n",
    "outlier_min=residuo_min[outcome]\n",
    "outlier_maximo=residuo_max[outcome]\n",
    "\n",
    "df_filtrado = df[(df[outcome] == outlier_min) | (df[outcome] == outlier_maximo)]\n",
    "\n",
    "print(f'el valor atipico minimo en la variable Y es {outlier_min}\\\n",
    " el valor atipico maximo en la variable Y es {outlier_maximo} '      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores atípicos en la variable **Y**, con un mínimo de **76** y un máximo de **100**, indican la presencia de puntos extremos derivados de los residuos estandarizados del modelo. Estos puntos atípicos pueden tener un impacto significativo en el análisis de los datos y, por lo tanto, deben ser revisados cuidadosamente.\n",
    "\n",
    "En el dataframe, los valores atípicos identificados corresponden a las observaciones con índices **3** y **16**, con valores de **Y** de **76** y **100**, respectivamente. Es esencial evaluar el contexto de estos valores para determinar si representan un fenómeno válido o si podrían estar distorsionando el ajuste del modelo. En caso de que estos valores atípicos resulten de errores o de datos no confiables, sería conveniente considerarlos para su posible eliminación o tratamiento adecuado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>Los valores atípicos en la variable Y, con un mínimo de 76 y un máximo de 100, indican que hay puntos extremos extraídos de los residuos estandarizados del modelo, que podrían influir en el análisis de los datos. Es importante considerar el contexto de estos valores y su impacto en el modelo.\n",
    "\n",
    ">>los valores atipicos filtrados en el dataframe son valores Y 76 y Y 100 con indixe 3 y 16 respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "3    76  101  117   93   95\n",
       "16  100  104   83  100  102"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores atipicos filtrados en el data set \n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Valores influyentes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene las distancias de Cook para cada observación\n",
    "cooks_d = influencia.cooks_distance[0]\n",
    "#Calcula el umbral para identificar puntos influyentes\n",
    "umbral=4/(len(df['Y'])-(df.shape[1]-1))\n",
    "# Identifica los índices de las observaciones \n",
    "# cuya distancia de Cook excede el umbral definido\n",
    "puntos_de_influencia=np.where(cooks_d>umbral)[0]\n",
    "#Extrae las distancias de Cook para esos puntos influyentes\n",
    "cooks_d[puntos_de_influencia]\n",
    "#Filtra el DataFrame para obtener las observaciones influyentes\n",
    "observaciones_influyentes = df.iloc[puntos_de_influencia]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los resultados obtenidos, se ha identificado un valor influyente de **0.191284**, ya que supera el umbral de **0.19047619**. Este valor corresponde a la observación con índice **15** en el dataframe, con los siguientes valores de las variables: \n",
    "\n",
    "- **Y**: 109\n",
    "- **X1**: 109\n",
    "- **X2**: 129\n",
    "- **X3**: 102\n",
    "- **X4**: 108\n",
    "\n",
    "La identificación de valores influyentes es crucial para garantizar la integridad del modelo, ya que estos puntos pueden alterar significativamente los resultados. En este caso, es recomendable considerar acciones como la eliminación de la observación si se determina que los datos son errores o provienen de información no confiable. Sin embargo, se debe realizar una evaluación adicional para confirmar si la observación refleja una situación válida o si representa un error de medición.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>en el resultado de valores influyentes se encuentra el valor 0.191284 se considera valor influyente  ya que esta por encima del valor del umbral 0.19047619. si se filtra influyentes en el dataframe seria el dato con indice 15,  con datos 109\t109\t129\t102\t108 con variables Y\tX1\tX2\tX3\tX4 respectivamente, las posibles acciones aconsiderar es eliminar las observaciones SI SON errores de informacion no confiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>129</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "15  109  109  129  102  108"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores influyentes filtrados data set\n",
    "observaciones_influyentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Punto de balanceo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_leverage = 2 * (df[['X1', 'X2', 'X3', 'X4']].shape[1] / len(df))\n",
    "leverage = influencia.hat_matrix_diag\n",
    "\n",
    "# Identificar los puntos de balanceo\n",
    "puntos_de_balanceo = np.where(leverage > umbral_leverage)[0]\n",
    "\n",
    "# Filtrar el DataFrame para obtener las observaciones de balanceo\n",
    "observaciones_balanceo = df.iloc[puntos_de_balanceo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos de balanceo son observaciones en las variables **X1**, **X2**, **X3** o **X4** que tienen el potencial de influir significativamente en los resultados de un modelo. La identificación de estos puntos es esencial para asegurar que el modelo no esté sesgado por un conjunto reducido de datos que pueda distorsionar las conclusiones generales.\n",
    "\n",
    "El procedimiento realizado para identificar estos valores tiene como objetivo verificar que no existan puntos de balanceo que estén ejerciendo una influencia desproporcionada sobre el modelo. Revisar estos valores ayuda a garantizar que los resultados sean representativos del conjunto de datos en su totalidad y que no estén dominados por observaciones particulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>Los puntos de balanceo son observaciones en (X1, X2, X3 o X4) que pueden influir significativamente en los resultados de un modelo. se realiza un procedimiento para Identificar esos valores con el fin de revisar que el modelo no esta sesgados por unos pocos datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>97</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>120</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y   X1  X2  X3   X4\n",
       "1  80   62  97  99  100\n",
       "6  58  120  77  80   74"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observaciones_balanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Análisis Comparativo de Modelos: Eliminando datos atipicos, influyentes y balanceo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se desarrollaron cinco modelos de regresión lineal para analizar el conjunto de datos, considerando tanto la inclusión como la exclusión de valores atípicos, influyentes y de balanceo. En la primera fase, se construyó un modelo utilizando **todos los datos disponibles**, lo que permitió captar la tendencia general y las relaciones entre las variables.\n",
    "\n",
    "1. **Modelo con todos los datos (modelo_all_variables)**\n",
    "2. **Modelo con datos atípicos eliminados (Modelo_sin_atipicos)**.\n",
    "3. **Modelo con datos influyentes eliminados (Modelo_sin_influyentes)**\n",
    "3. **Modelo con datos balanceo eliminados (Modelo_sin_balanceo)**.\n",
    "3. **Modelo con todos los datos atípicos, influyentes y de balanceo eliminados (Sin_all_errores )**.\n",
    "\n",
    "Esta metodología de comparación permitió evaluar la robustez de los enfoques y analizar cómo la presencia de datos extremos afecta la interpretación de los resultados. Los diferentes enfoques ofrecieron una perspectiva más completa sobre cómo los valores extremos pueden influir en las predicciones del modelo, proporcionando una base sólida para tomar decisiones sobre el manejo de estos puntos en análisis futuros.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>se llevaron a cabo cinco modelos de regresión lineal para analizar el conjunto de datos, abordando tanto la inclusión como la exclusión de datos atípicos,influyentes y balanceo. En la primera fase, se desarrolló un modelo utilizando todos los datos disponibles, lo que permitió observar la tendencia general y la relación entre las variables. Posteriormente, se realizo el modelo con datos atipicos eliminados y  un modelo borrando los datos influyentes y datos de balanceo, por ultimo se creo un modelo donde se eliminaron todos los datos atipos,influyentes  y de balanceo en un mismo modelo, Esta metodología nos permitió comparar la robustez de los cuatro enfoques y evaluar cómo la presencia de estos datos extremos puede afectar la interpretación de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar=df.copy()\n",
    "# se eliminan los valores atipicos encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar.drop(index=[3, 16], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_atipicos=sm.OLS(df_eliminar[outcome],df_eliminar[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_2=modelo_atipicos.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_2=df.copy()\n",
    "# se eliminan los valores influyentes encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_2.drop(index=[15], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_influyentes=sm.OLS(df_eliminar_2[outcome],df_eliminar_2[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_3=modelo_influyentes.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_4=df.copy()\n",
    "# se eliminan los valores de balanceo encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_4.drop(index=[1,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_balanceo=sm.OLS(df_eliminar_4[outcome],df_eliminar_4[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_4=modelo_balanceo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_5=df.copy()\n",
    "# se eliminan todos los  encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_5.drop(index=[3,16,15,1,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_balanceo=sm.OLS(df_eliminar_5[outcome],df_eliminar_5[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_5=modelo_balanceo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cuadro resumen de los criterios de los modelos** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo_all_variables</th>\n",
       "      <th>Modelo_sin_atipicos</th>\n",
       "      <th>Modelo_sin_influyentes</th>\n",
       "      <th>Modelo_sin_balanceo</th>\n",
       "      <th>Sin_all_arrores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.962892</td>\n",
       "      <td>0.971449</td>\n",
       "      <td>0.966514</td>\n",
       "      <td>0.956046</td>\n",
       "      <td>0.969393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 ajus</th>\n",
       "      <td>0.955470</td>\n",
       "      <td>0.965105</td>\n",
       "      <td>0.959464</td>\n",
       "      <td>0.946279</td>\n",
       "      <td>0.961231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f stad</th>\n",
       "      <td>129.741157</td>\n",
       "      <td>153.114579</td>\n",
       "      <td>137.099986</td>\n",
       "      <td>97.880728</td>\n",
       "      <td>118.769310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>145.901138</td>\n",
       "      <td>130.072863</td>\n",
       "      <td>138.187575</td>\n",
       "      <td>136.940795</td>\n",
       "      <td>114.350413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bic</th>\n",
       "      <td>151.995517</td>\n",
       "      <td>135.750334</td>\n",
       "      <td>144.077845</td>\n",
       "      <td>142.618266</td>\n",
       "      <td>119.329074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Modelo_all_variables  Modelo_sin_atipicos  Modelo_sin_influyentes  \\\n",
       "r2                   0.962892             0.971449                0.966514   \n",
       "r2 ajus              0.955470             0.965105                0.959464   \n",
       "f stad             129.741157           153.114579              137.099986   \n",
       "AIC                145.901138           130.072863              138.187575   \n",
       "Bic                151.995517           135.750334              144.077845   \n",
       "\n",
       "         Modelo_sin_balanceo  Sin_all_arrores  \n",
       "r2                  0.956046         0.969393  \n",
       "r2 ajus             0.946279         0.961231  \n",
       "f stad             97.880728       118.769310  \n",
       "AIC               136.940795       114.350413  \n",
       "Bic               142.618266       119.329074  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadro = {\n",
    "    'Modelo_all_variables': {'r2': resultado_1.rsquared, 'r2 ajus':resultado_1.rsquared_adj\n",
    "    ,'f stad':resultado_1.fvalue,'AIC':resultado_1.aic,'Bic': resultado_1.bic},\n",
    "    'Modelo_sin_atipicos': {'r2': resultado_2.rsquared, 'r2 ajus':resultado_2.rsquared_adj\n",
    "    ,'f stad':resultado_2.fvalue,'AIC':resultado_2.aic,\n",
    "    'Bic': resultado_2.bic,\n",
    "    }, 'Modelo_sin_influyentes': {'r2': resultado_3.rsquared, 'r2 ajus':resultado_3.rsquared_adj\n",
    "      ,'f stad':resultado_3.fvalue,'AIC':resultado_3.aic,\n",
    "    'Bic': resultado_3.bic,\n",
    "    }, 'Modelo_sin_balanceo': {'r2': resultado_4.rsquared, 'r2 ajus':resultado_4.rsquared_adj\n",
    "      ,'f stad':resultado_4.fvalue,'AIC':resultado_4.aic, 'Bic': resultado_4.bic,\n",
    "      }, 'Sin_all_arrores': {'r2': resultado_5.rsquared, 'r2 ajus':resultado_5.rsquared_adj\n",
    "      ,'f stad':resultado_5.fvalue,'AIC':resultado_5.aic, 'Bic': resultado_5.bic,     \n",
    "    \n",
    "}}\n",
    "resumen=pd.DataFrame(cuadro)\n",
    "resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se presentan las métricas clave para comparar los diferentes modelos de regresión lineal según las modificaciones realizadas en los datos (eliminación de datos atípicos, influyentes y de balanceo):\n",
    "\n",
    "- **R²**: El modelo sin datos atípicos muestra el mejor ajuste, con un valor de **0.971449**, lo que indica que este modelo explica la mayor proporción de la varianza en la variable dependiente.\n",
    "  \n",
    "- **R² Ajustado**: De manera similar, el modelo sin datos atípicos tiene el mejor ajuste ajustado con **0.965105**, lo que confirma que sigue siendo el modelo más robusto incluso al ajustar por el número de predictores.\n",
    "\n",
    "- **F-Statistic**: El modelo sin datos atípicos también exhibe una mayor significancia estadística con un valor de **153.114**, lo que sugiere que explica significativamente más de la variabilidad en la variable dependiente en comparación con el error.\n",
    "\n",
    "- **AIC**: El modelo sin datos atípicos, influyentes y de balanceo tiene el AIC más bajo, con un valor de **114.350413**, indicando que este modelo penaliza menos la complejidad y es más eficiente en términos de ajuste y parsimonia.\n",
    "\n",
    "- **BIC**: De manera consistente, el modelo sin datos atípicos, influyentes y de balanceo tiene el BIC más bajo, con **119.329074**, favoreciendo modelos más simples y penalizando la complejidad excesiva.\n",
    "\n",
    "En conclusión, si se busca un modelo más **simple e interpretativo**, optar por el modelo que excluye datos atípicos, influyentes y de balanceo parece ser la mejor opción, ya que ofrece un buen ajuste con menor riesgo de sobreajuste. Sin embargo, si el objetivo principal es **maximizar la precisión predictiva** y preservar la interpretación de los datos originales, mantener un modelo con todos los datos puede ser preferible. La falta de cambios significativos en criterios como el **R²** sugiere que la eliminación de estos datos extremos no es absolutamente necesaria para todos los casos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2: el modelo sin datos atipicos tiene el mejor ajuste con 0.971449 \n",
    "\n",
    "R2 AJUSTADO: el modelo sin datos atipicos tiene un mejor ajuste con 0.965105\n",
    "\n",
    "F STAD: el modelo sin datos atipicos muestra una mayor significancia con un valor de 153.114 por lo que el modelo explica significativamente más  la variable dependiente en comparación con el error.\n",
    "\n",
    "AIC: el modelo sin los datos atipicos,influyentes y balanceo tiene el AIC mas bajo 114.350413 lo que indica que el modelo penaliza menos por complejidad \n",
    "\n",
    "BIC: el modelo sin los datos atipicos,influyentes y balanceo (sin_all_arrores) tiene el BIC mas bajo 119.329074  que tiende a favorecer modelos más simples.\n",
    "\n",
    "Si la necesidad es un modelo más simple y interpretativo, optar por el modelo sin datos atípicos,influyentes y balanceo  podría ser la mejor decisión, ya que ofrece una buena calidad de ajuste con un menor riesgo de sobreajuste con el modelo sin_all_arrores. Sin embargo, si el objetivo principal es maximizar la precisión predictiva y la interpretación de los datos originales es crucial, mantener los modelos que incluyen todos los datos. por lo que la falta de cambios significativos en los criterios tipo R² sugiere que la eliminación de datos puede no ser absolutamente necesaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 3**\n",
    "\n",
    "Realice la prueba de significancia del modelo, interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se saca el p valor del modelo\n",
    "p_value_modelo = resultado_1.f_pvalue\n",
    "\n",
    "# Obtener coeficientes y valores p\n",
    "coeficientes = resultado_1.params\n",
    "valores_p = resultado_1.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Análisis** \n",
    "\n",
    "Se evaluó la significancia del modelo utilizando el valor **p** y los coeficientes de las variables independientes **X1**, **X2**, **X3** y **X4**. Los resultados muestran lo siguiente:\n",
    "\n",
    "- **Valor p del modelo**: El valor **p** obtenido es de **5.26×10⁻¹⁴**, que está muy por debajo del umbral común de **0.05**. Esto indica que el modelo es significativo en su conjunto, sugiriendo que las variables **X** están explicando variabilidad en **Y** de manera estadísticamente significativa.\n",
    "  \n",
    "- **R²**: El coeficiente de determinación **R²** es de **96.29%**, lo que sugiere que el modelo ajusta bien a los datos, explicando la mayor parte de la variabilidad de la variable dependiente **Y**.\n",
    "\n",
    "Las variables se evaluaron en función de su valor **p**, donde un valor **p** menor a **0.05** se considera indicativo de significancia:\n",
    "\n",
    "- **X1**: **0.000** (significativo)\n",
    "- **X2**: **0.404** (no significativo)\n",
    "- **X3**: **0.000** (significativo)\n",
    "- **X4**: **0.001** (significativo)\n",
    "\n",
    "Esto sugiere que **X1**, **X3** y **X4** son las variables más relevantes en el modelo, mientras que **X2** no tiene un efecto significativo sobre la habilidad laboral, dado su valor **p** mayor a **0.05**.\n",
    "\n",
    "Los coeficientes estimados para las variables son:\n",
    "\n",
    "- **X1**: **0.2957**\n",
    "- **X2**: **0.0483**\n",
    "- **X3**: **1.3060**\n",
    "- **X4**: **0.5198**\n",
    "\n",
    "Todos los coeficientes son positivos, lo que indica que las variables tienen una relación positiva con la habilidad laboral. Sin embargo, **X3** tiene el coeficiente más alto, lo que sugiere que es la variable con el mayor efecto sobre la habilidad laboral.\n",
    "\n",
    "El análisis muestra que **X1**, **X3** y **X4** son variables significativas para explicar la habilidad laboral, siendo **X3** la que tiene el mayor impacto. Dado que **X2** no es significativa (valor **p** de **0.404**), se podría considerar la posibilidad de eliminarla del modelo para simplificarlo sin perder capacidad explicativa. Focalizarse en mejorar o entender mejor **X1**, **X3** y **X4** podría tener un impacto considerable en la habilidad laboral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un valor p de 5.26×10−14  esta por debajo del umbral común de 0.05, Esto sugiere que el modelo es significativo en su conjunto y que las variables de X están explicando variabilidad en Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " por otro lado el R2 con un valor aproximadamente del 96.29% de la variabilidad de la variable dependiente,se puede explicar que el modelo tiene un buen ajuste a los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se evaluo las variables x en funcion de los criterios valor p y el coeficiente, siendo el valor p como indicador principal de significancia, en el que se considera el valor p inferior de 0.05  una variable con relevancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1       0.000\n",
    "\n",
    "X2       0.404\n",
    "\n",
    "X3       0.000\n",
    "\n",
    "X4       0.001\n",
    "\n",
    "el valor p para x1 y x3 es de 0.000, dado que el valor p es menor a 0.05 existe evidencia para concluir que x1 y x3 tiene un efecto significativo en la habilidad laboral, x2  siguen una tendencia de un un valor p de 0.404  respectivamente, indicando que existe un efecto significativo en la habilidad laboral, y para x4 muestra una relacion positiva con un valor p de 0.001.\n",
    "\n",
    "esto sugiere que las variables mas relevantes para el modelo es x1, x3 y x4.\n",
    "\n",
    "los coeficientes\n",
    "\n",
    "X1       0.2957\n",
    "\n",
    "X2       0.0483\n",
    "\n",
    "X3       1.3060\n",
    "\n",
    "X4       0.5198\n",
    "\n",
    "Todas las variables tienen coeficientes positivos,sin embargo X3 tiene el coeficiente más alto, indicando que es la variable con el efecto más fuerte sobre las habilidad laborales.\n",
    "\n",
    "conclucion \n",
    "\n",
    "el análisis revela que X1, X3 y X4 son variables significativas en la habilidad laboral, con X3 mostrando el efecto más fuerte. \n",
    "\n",
    "La evidencia sugiere que centrarse en mejorar o entender mejor X1, X3 y X4 podría tener un impacto notable en la habilidad laboral asi mismo se puede considerar la posibilidad de eliminar la variable x2 del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 4**\n",
    "\n",
    "Obtener el coeficiente de determinación y el coeficiente de determinación ajustado. Interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 5**\n",
    "\n",
    "Analice si hay problemas de multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variable       VIF\n",
      "0       X1  1.138043\n",
      "1       X2  1.369512\n",
      "2       X3  3.016549\n",
      "3       X4  2.834776\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que tienes un DataFrame llamado df con tus variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "# Estandarizar las variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[variables])\n",
    "\n",
    "# Calcular el VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = variables\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 6**\n",
    "Realice una selección e variables por el método que prefiera, tome decisiones, explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Optimización del Modelo**\n",
    "\n",
    "El objetivo principal es identificar el mejor modelo posible mediante un proceso de **selección de variables**, equilibrando la complejidad del modelo y su capacidad de ajuste a los datos. Para ello, se ha utilizado el criterio de información de Akaike (**AIC**), que penaliza los modelos más complejos y favorece aquellos que logran un equilibrio adecuado entre ajuste y simplicidad.\n",
    "\n",
    "El uso del **AIC** permite determinar qué variables tienen un impacto significativo en los resultados del modelo predictivo. A través de este enfoque, se busca identificar las variables que contribuyen de manera relevante al ajuste del modelo, eliminando aquellas que no mejoran la precisión predictiva o que introducen complejidad innecesaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>el objetivo es encontrar el mejor modelo posible mediante selección de variables, optimizando la complejidad y el ajuste a los datos por medio de el criterio AIC. Esto permite identificar cuáles variables tienen un impacto significativo en el resultado en el desarrollo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: X1, X2, X3, X4\n",
      "Start: score=222.25, constant\n",
      "Step: score=183.42, add X3\n",
      "Step: score=158.67, add X1\n",
      "Step: score=146.79, add X4\n",
      "Step: score=146.79, unchanged None\n",
      "\n",
      "Intercept: -124.2000165715195\n",
      "Coefficients:\n",
      " X3: 1.357\n",
      " X1: 0.2963\n",
      " X4: 0.5174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#  variable dependiente o a predecir\n",
    "y = df[outcome]\n",
    "\n",
    "# variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "\n",
    "# se crea una funcion donde esta almacenado el modelo de regresion lineal \n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[variables], y)  # Ajustar el modelo con las variables X1, X2, X3, X4\n",
    "    return model\n",
    "\n",
    "# se Calcula el AIC usando las predicciones del modelo\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(y, [y.mean()] * len(y), model, df=1)\n",
    "    return AIC_score(y, model.predict(df[variables]), model)\n",
    "\n",
    " \n",
    "# Aquí se pasan las variables específicas para la selección\n",
    "# penalizando la complejidad del modelo para evitar el sobreajuste\n",
    "# utilizando la funcion stepwise_selection de la libreria dmba se seleciona las mejores varuables \n",
    "best_model, best_variables = stepwise_selection(variables, train_model, score_model, \n",
    "                                                verbose=True)\n",
    "\n",
    "# Imprimir resultados\n",
    "print()\n",
    "print(f'Intercept: {best_model.intercept_}')\n",
    "print('Coefficients:')\n",
    "for name, coef in zip(best_variables, best_model.coef_):\n",
    "    print(f' {name}: {round(coef,4)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El **modelo final** incluye las variables **X1**, **X3** y **X4**, ya que la inclusión de **X2** no mejoró significativamente el ajuste del modelo. Este enfoque optimiza tanto el ajuste a los datos como la complejidad del modelo, priorizando las variables que tienen un impacto significativo.\n",
    "\n",
    "Un **modelo más simple** que solo incluye las variables relevantes no solo facilita la interpretación de los resultados, sino que también reduce el riesgo de **sobreajuste**. El sobreajuste ocurre cuando el modelo se ajusta demasiado a los datos de entrenamiento, lo que compromete su capacidad de generalización a nuevos datos. Al excluir variables innecesarias, se mejora la robustez del modelo, haciéndolo más confiable y eficiente en situaciones predictivas.\n",
    "\n",
    "El enfoque final, que excluye la variable **X2**, optimiza el balance entre la precisión predictiva y la simplicidad, asegurando un modelo más interpretativo y con menor riesgo de sobreajuste. Este resultado sugiere que enfocarse en las variables **X1**, **X3** y **X4** es suficiente para lograr un buen rendimiento sin añadir complejidad innecesaria.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>el modelo final incluye las variables x1,x3,x4 La inclusión de X2 no mejoró el modelo, este enfoque optimiza tanto el ajuste como la complejidad del modelo. Un modelo más simple, que solo incluya variables relevantes, no solo facilita la interpretación, sino que también reduce el riesgo de sobreajuste, donde el modelo se ajusta demasiado a los datos de entrenamiento y pierde capacidad de generalización en nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **Punto 7**\n",
    "Realice una predicción utilizando el modelo seleccionado, interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
