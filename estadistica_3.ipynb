{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dmba import stepwise_selection\n",
    "from dmba import AIC_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='c:/Users/afonseca/Downloads/laboral.csv'\n",
    "df=pd.read_csv(url,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Emplee el análisis de regresión lineal múltiple que explique la habilidad laboral en términos de las variables res-tantes (actuando como predictoras Xi).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   129.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 02 Oct 2024</td> <th>  Prob (F-statistic):</th> <td>5.26e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:05:44</td>     <th>  Log-Likelihood:    </th> <td> -67.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    25</td>      <th>  AIC:               </th> <td>   145.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   152.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    0.2957</td> <td>    0.044</td> <td>    6.725</td> <td> 0.000</td> <td>    0.204</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    0.0483</td> <td>    0.057</td> <td>    0.853</td> <td> 0.404</td> <td>   -0.070</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td>    1.3060</td> <td>    0.164</td> <td>    7.959</td> <td> 0.000</td> <td>    0.964</td> <td>    1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>    <td>    0.5198</td> <td>    0.132</td> <td>    3.940</td> <td> 0.001</td> <td>    0.245</td> <td>    0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -124.3818</td> <td>    9.941</td> <td>  -12.512</td> <td> 0.000</td> <td> -145.119</td> <td> -103.645</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.256</td> <th>  Durbin-Watson:     </th> <td>   1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.196</td> <th>  Jarque-Bera (JB):  </th> <td>   1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.139</td> <th>  Prob(JB):          </th> <td>   0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.867</td> <th>  Cond. No.          </th> <td>2.47e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.47e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        Y         & \\textbf{  R-squared:         } &     0.963   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.955   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     129.7   \\\\\n",
       "\\textbf{Date:}             & Wed, 02 Oct 2024 & \\textbf{  Prob (F-statistic):} &  5.26e-14   \\\\\n",
       "\\textbf{Time:}             &     14:05:44     & \\textbf{  Log-Likelihood:    } &   -67.951   \\\\\n",
       "\\textbf{No. Observations:} &          25      & \\textbf{  AIC:               } &     145.9   \\\\\n",
       "\\textbf{Df Residuals:}     &          20      & \\textbf{  BIC:               } &     152.0   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{X1}    &       0.2957  &        0.044     &     6.725  &         0.000        &        0.204    &        0.387     \\\\\n",
       "\\textbf{X2}    &       0.0483  &        0.057     &     0.853  &         0.404        &       -0.070    &        0.166     \\\\\n",
       "\\textbf{X3}    &       1.3060  &        0.164     &     7.959  &         0.000        &        0.964    &        1.648     \\\\\n",
       "\\textbf{X4}    &       0.5198  &        0.132     &     3.940  &         0.001        &        0.245    &        0.795     \\\\\n",
       "\\textbf{const} &    -124.3818  &        9.941     &   -12.512  &         0.000        &     -145.119    &     -103.645     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.256 & \\textbf{  Durbin-Watson:     } &    1.148  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.196 & \\textbf{  Jarque-Bera (JB):  } &    1.419  \\\\\n",
       "\\textbf{Skew:}          &  0.139 & \\textbf{  Prob(JB):          } &    0.492  \\\\\n",
       "\\textbf{Kurtosis:}      &  1.867 & \\textbf{  Cond. No.          } & 2.47e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.47e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.963\n",
       "Model:                            OLS   Adj. R-squared:                  0.955\n",
       "Method:                 Least Squares   F-statistic:                     129.7\n",
       "Date:                Wed, 02 Oct 2024   Prob (F-statistic):           5.26e-14\n",
       "Time:                        14:05:44   Log-Likelihood:                -67.951\n",
       "No. Observations:                  25   AIC:                             145.9\n",
       "Df Residuals:                      20   BIC:                             152.0\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
       "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
       "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
       "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
       "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
       "==============================================================================\n",
       "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
       "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
       "Skew:                           0.139   Prob(JB):                        0.492\n",
       "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome='Y'\n",
    "modelo=sm.OLS(df[outcome],df[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_1=modelo.fit()\n",
    "resultado_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1: por cada aumento de una unidad en x1, la habilidad laboral aumenta 0.2957 y asi mismo es estadisticamente significativo, para x2 tiene un coheficiente pequeño de 0.0483 con un  p valor de 0.404  lo que sugiere que el x2 no tiene una relacion relevante con la habilidad laboral y se puede sugerir para posteriores analisis eliminar la variable,  coefciente x4 es de 0.5198 lo que tambien indica una relacion positiva y con un un valor p del 0.001, el cual es significativo lo que indica una fuerte relacion con la habilidad laboral, y por ultimo x3 muestra la relacion mas fuerte positiva 1.3060 y un valor p 0.000 significativo el cual sugiere que es la variable con mayor relacion positiva frente a la habilidad laboral habilidad laboral "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Identifique observaciones que puedan considerarse problemáticas (datos atípicos, puntos de balanceo e influ- yentes) y analice si debe eliminarlas de su conjunto de datos o no, justifique. Repita la construcción del modelode regresión si eliminó observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea un modelo de regresión lineal  usando 'outcome' \n",
    "#como variable dependiente y las variables independientes X1, X2, X3 y X4.\n",
    "modelo=sm.OLS(df[outcome],df[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado=modelo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "#Crea un objeto de influencia a partir de los resultados del modelo de regresión\n",
    "influencia=OLSInfluence(resultado)\n",
    "#Extrae los residuos estandarizados del modelo\n",
    "residuals=influencia.resid_studentized_internal\n",
    "# Localiza la fila del DataFrame con el residuo estandarizado más alto y bajo\n",
    "residuo_max=df.loc[residuals.idxmax(),:]\n",
    "residuo_min=df.loc[residuals.idxmin(),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor atipico minimo en la variable Y es 76 el valor atipico maximo en la variable Y es 100 \n"
     ]
    }
   ],
   "source": [
    "#Extrae el valor del resultado (Y) correspondiente al residuo mínimo y maximo\n",
    "outlier_min=residuo_min[outcome]\n",
    "outlier_maximo=residuo_max[outcome]\n",
    "\n",
    "df_filtrado = df[(df[outcome] == outlier_min) | (df[outcome] == outlier_maximo)]\n",
    "\n",
    "print(f'el valor atipico minimo en la variable Y es {outlier_min}\\\n",
    " el valor atipico maximo en la variable Y es {outlier_maximo} '      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores atípicos en la variable Y, con un mínimo de 76 y un máximo de 100, indican que hay puntos extremos extraídos de los residuos estandarizados del modelo, que podrían influir en el análisis de los datos. Es importante considerar el contexto de estos valores y su impacto en el modelo.\n",
    "\n",
    "los valores atipicos filtrados en el dataframe son valores Y 76 y Y 100 con indixe 3 y 16 respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "3    76  101  117   93   95\n",
       "16  100  104   83  100  102"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores atipicos filtrados en el data set \n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores influyentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene las distancias de Cook para cada observación\n",
    "cooks_d = influencia.cooks_distance[0]\n",
    "#Calcula el umbral para identificar puntos influyentes\n",
    "umbral=4/(len(df['Y'])-(df.shape[1]-1))\n",
    "# Identifica los índices de las observaciones \n",
    "# cuya distancia de Cook excede el umbral definido\n",
    "puntos_de_influencia=np.where(cooks_d>umbral)[0]\n",
    "#Extrae las distancias de Cook para esos puntos influyentes\n",
    "cooks_d[puntos_de_influencia]\n",
    "#Filtra el DataFrame para obtener las observaciones influyentes\n",
    "observaciones_influyentes = df.iloc[puntos_de_influencia]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "en el resultado de valores influyentes se encuentra el valor 0.191284 se considera valor influyente  ya que esta por encima del valor del umbral 0.19047619. si se filtra influyentes en el dataframe seria el dato con indice 15,  con datos 109\t109\t129\t102\t108 con variables Y\tX1\tX2\tX3\tX4 respectivamente, las posibles acciones aconsiderar es eliminar las observaciones SI SON errores de informacion no confiable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>129</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "15  109  109  129  102  108"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores influyentes filtrados data set\n",
    "observaciones_influyentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "punto de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_leverage = 2 * (df[['X1', 'X2', 'X3', 'X4']].shape[1] / len(df))\n",
    "leverage = influencia.hat_matrix_diag\n",
    "\n",
    "# Identificar los puntos de balanceo\n",
    "puntos_de_balanceo = np.where(leverage > umbral_leverage)[0]\n",
    "\n",
    "# Filtrar el DataFrame para obtener las observaciones de balanceo\n",
    "observaciones_balanceo = df.iloc[puntos_de_balanceo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos de balanceo son observaciones en (X1, X2, X3 o X4) que pueden influir significativamente en los resultados de un modelo. se realiza un procedimiento para Identificar esos valores con el fin de revisar que el modelo no esta sesgados por unos pocos datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80</td>\n",
       "      <td>62</td>\n",
       "      <td>97</td>\n",
       "      <td>99</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>120</td>\n",
       "      <td>77</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Y   X1  X2  X3   X4\n",
       "1  80   62  97  99  100\n",
       "6  58  120  77  80   74"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observaciones_balanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelos eliminando datos atipicos, influyentes y balanceo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "se llevaron a cabo cinco modelos de regresión lineal para analizar el conjunto de datos, abordando tanto la inclusión como la exclusión de datos atípicos,influyentes y balanceo. En la primera fase, se desarrolló un modelo utilizando todos los datos disponibles, lo que permitió observar la tendencia general y la relación entre las variables. Posteriormente, se realizo el modelo con datos atipicos eliminados y  un modelo borrando los datos influyentes y datos de balanceo, por ultimo se creo un modelo donde se eliminaron todos los datos atipos,influyentes  y de balanceo en un mismo modelo, Esta metodología nos permitió comparar la robustez de los cuatro enfoques y evaluar cómo la presencia de estos datos extremos puede afectar la interpretación de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar=df.copy()\n",
    "# se eliminan los valores atipicos encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar.drop(index=[3, 16], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_atipicos=sm.OLS(df_eliminar[outcome],df_eliminar[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_2=modelo_atipicos.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_2=df.copy()\n",
    "# se eliminan los valores influyentes encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_2.drop(index=[15], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_influyentes=sm.OLS(df_eliminar_2[outcome],df_eliminar_2[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_3=modelo_influyentes.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_4=df.copy()\n",
    "# se eliminan los valores de balanceo encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_4.drop(index=[1,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_balanceo=sm.OLS(df_eliminar_4[outcome],df_eliminar_4[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_4=modelo_balanceo.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_5=df.copy()\n",
    "# se eliminan todos los  encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_5.drop(index=[3,16,15,1,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_balanceo=sm.OLS(df_eliminar_5[outcome],df_eliminar_5[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_5=modelo_balanceo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuadro resumen de los criterios de los modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo_all_variables</th>\n",
       "      <th>modelo_sin_atipicos</th>\n",
       "      <th>modelo_sin_influyentes</th>\n",
       "      <th>modelo_sin_balanceo</th>\n",
       "      <th>sin_all_arrores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.962892</td>\n",
       "      <td>0.971449</td>\n",
       "      <td>0.966514</td>\n",
       "      <td>0.956046</td>\n",
       "      <td>0.969393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 ajus</th>\n",
       "      <td>0.955470</td>\n",
       "      <td>0.965105</td>\n",
       "      <td>0.959464</td>\n",
       "      <td>0.946279</td>\n",
       "      <td>0.961231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f stad</th>\n",
       "      <td>129.741157</td>\n",
       "      <td>153.114579</td>\n",
       "      <td>137.099986</td>\n",
       "      <td>97.880728</td>\n",
       "      <td>118.769310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>145.901138</td>\n",
       "      <td>130.072863</td>\n",
       "      <td>138.187575</td>\n",
       "      <td>136.940795</td>\n",
       "      <td>114.350413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bic</th>\n",
       "      <td>151.995517</td>\n",
       "      <td>135.750334</td>\n",
       "      <td>144.077845</td>\n",
       "      <td>142.618266</td>\n",
       "      <td>119.329074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         modelo_all_variables  modelo_sin_atipicos  modelo_sin_influyentes  \\\n",
       "r2                   0.962892             0.971449                0.966514   \n",
       "r2 ajus              0.955470             0.965105                0.959464   \n",
       "f stad             129.741157           153.114579              137.099986   \n",
       "AIC                145.901138           130.072863              138.187575   \n",
       "Bic                151.995517           135.750334              144.077845   \n",
       "\n",
       "         modelo_sin_balanceo  sin_all_arrores  \n",
       "r2                  0.956046         0.969393  \n",
       "r2 ajus             0.946279         0.961231  \n",
       "f stad             97.880728       118.769310  \n",
       "AIC               136.940795       114.350413  \n",
       "Bic               142.618266       119.329074  "
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadro = {\n",
    "    'modelo_all_variables': {'r2': resultado_1.rsquared, 'r2 ajus':resultado_1.rsquared_adj\n",
    "    ,'f stad':resultado_1.fvalue,'AIC':resultado_1.aic,'Bic': resultado_1.bic},\n",
    "    'modelo_sin_atipicos': {'r2': resultado_2.rsquared, 'r2 ajus':resultado_2.rsquared_adj\n",
    "    ,'f stad':resultado_2.fvalue,'AIC':resultado_2.aic,\n",
    "    'Bic': resultado_2.bic,\n",
    "    }, 'modelo_sin_influyentes': {'r2': resultado_3.rsquared, 'r2 ajus':resultado_3.rsquared_adj\n",
    "      ,'f stad':resultado_3.fvalue,'AIC':resultado_3.aic,\n",
    "    'Bic': resultado_3.bic,\n",
    "    }, 'modelo_sin_balanceo': {'r2': resultado_4.rsquared, 'r2 ajus':resultado_4.rsquared_adj\n",
    "      ,'f stad':resultado_4.fvalue,'AIC':resultado_4.aic, 'Bic': resultado_4.bic,\n",
    "      }, 'sin_all_arrores': {'r2': resultado_5.rsquared, 'r2 ajus':resultado_5.rsquared_adj\n",
    "      ,'f stad':resultado_5.fvalue,'AIC':resultado_5.aic, 'Bic': resultado_5.bic,     \n",
    "    \n",
    "}}\n",
    "resumen=pd.DataFrame(cuadro)\n",
    "resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R2: el modelo sin datos atipicos tiene el mejor ajuste con 0.971449 \n",
    "\n",
    "R2 AJUSTADO: el modelo sin datos atipicos tiene un mejor ajuste con 0.965105\n",
    "\n",
    "F STAD: el modelo sin datos atipicos muestra una mayor significancia con un valor de 153.114 por lo que el modelo explica significativamente más  la variable dependiente en comparación con el error.\n",
    "\n",
    "AIC: el modelo sin los datos atipicos,influyentes y balanceo tiene el AIC mas bajo 114.350413 lo que indica que el modelo penaliza menos por complejidad \n",
    "\n",
    "BIC: el modelo sin los datos atipicos,influyentes y balanceo (sin_all_arrores) tiene el BIC mas bajo 119.329074  que tiende a favorecer modelos más simples.\n",
    "\n",
    "Si la necesidad es un modelo más simple y interpretativo, optar por el modelo sin datos atípicos,influyentes y balanceo  podría ser la mejor decisión, ya que ofrece una buena calidad de ajuste con un menor riesgo de sobreajuste con el modelo sin_all_arrores. Sin embargo, si el objetivo principal es maximizar la precisión predictiva y la interpretación de los datos originales es crucial, mantener los modelos que incluyen todos los datos. por lo que la falta de cambios significativos en los criterios tipo R² sugiere que la eliminación de datos puede no ser absolutamente necesaria\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Realice la prueba de significancia del modelo, interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se saca el p valor del modelo\n",
    "p_value_modelo = resultado_1.f_pvalue\n",
    "\n",
    "# Obtener coeficientes y valores p\n",
    "coeficientes = resultado_1.params\n",
    "valores_p = resultado_1.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un valor p de 5.26×10−14  esta por debajo del umbral común de 0.05, Esto sugiere que el modelo es significativo en su conjunto y que las variables de X están explicando variabilidad en Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " por otro lado el R2 con un valor aproximadamente del 96.29% de la variabilidad de la variable dependiente,se puede explicar que el modelo tiene un buen ajuste a los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se evaluo las variables x en funcion de los criterios valor p y el coeficiente, siendo el valor p como indicador principal de significancia, en el que se considera el valor p inferior de 0.05  una variable con relevancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1       0.000\n",
    "\n",
    "X2       0.404\n",
    "\n",
    "X3       0.000\n",
    "\n",
    "X4       0.001\n",
    "\n",
    "el valor p para x1 y x3 es de 0.000, dado que el valor p es menor a 0.05 existe evidencia para concluir que x1 y x3 tiene un efecto significativo en la habilidad laboral, x2  siguen una tendencia de un un valor p de 0.404  respectivamente, indicando que existe un efecto significativo en la habilidad laboral, y para x4 muestra una relacion positiva con un valor p de 0.001.\n",
    "\n",
    "esto sugiere que las variables mas relevantes para el modelo es x1, x3 y x4.\n",
    "\n",
    "los coeficientes\n",
    "\n",
    "X1       0.2957\n",
    "\n",
    "X2       0.0483\n",
    "\n",
    "X3       1.3060\n",
    "\n",
    "X4       0.5198\n",
    "\n",
    "Todas las variables tienen coeficientes positivos,sin embargo X3 tiene el coeficiente más alto, indicando que es la variable con el efecto más fuerte sobre las habilidad laborales.\n",
    "\n",
    "conclucion \n",
    "\n",
    "el análisis revela que X1, X3 y X4 son variables significativas en la habilidad laboral, con X3 mostrando el efecto más fuerte. \n",
    "\n",
    "La evidencia sugiere que centrarse en mejorar o entender mejor X1, X3 y X4 podría tener un impacto notable en la habilidad laboral asi mismo se puede considerar la posibilidad de eliminar la variable x2 del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtener el coeficiente de determinación y el coeficiente de determinación ajustado. Interprete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analice si hay problemas de multicolinealidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Variable       VIF\n",
      "0       X1  1.138043\n",
      "1       X2  1.369512\n",
      "2       X3  3.016549\n",
      "3       X4  2.834776\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df con tus variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "# Estandarizar las variables\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[variables])\n",
    "\n",
    "# Calcular el VIF para cada variable\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Variable'] = variables\n",
    "vif_data['VIF'] = [variance_inflation_factor(X_scaled, i) for i in range(X_scaled.shape[1])]\n",
    "\n",
    "# Mostrar resultados\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Realice una selección e variables por el método que prefiera, tome decisiones, explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el objetivo es encontrar el mejor modelo posible mediante selección de variables, optimizando la complejidad y el ajuste a los datos por medio de el criterio AIC. Esto permite identificar cuáles variables tienen un impacto significativo en el resultado en el desarrollo predictivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: X1, X2, X3, X4\n",
      "Start: score=222.25, constant\n",
      "Step: score=183.42, add X3\n",
      "Step: score=158.67, add X1\n",
      "Step: score=146.79, add X4\n",
      "Step: score=146.79, unchanged None\n",
      "\n",
      "Intercept: -124.20001657151936\n",
      "Coefficients:\n",
      " X3: 1.357\n",
      " X1: 0.2963\n",
      " X4: 0.5174\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#  variable dependiente o a predecir\n",
    "y = df[outcome]\n",
    "\n",
    "# variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "\n",
    "# se crea una funcion donde esta almacenado el modelo de regresion lineal \n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[variables], y)  # Ajustar el modelo con las variables X1, X2, X3, X4\n",
    "    return model\n",
    "\n",
    "# se Calcula el AIC usando las predicciones del modelo\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(y, [y.mean()] * len(y), model, df=1)\n",
    "    return AIC_score(y, model.predict(df[variables]), model)\n",
    "\n",
    " \n",
    "# Aquí se pasan las variables específicas para la selección\n",
    "# penalizando la complejidad del modelo para evitar el sobreajuste\n",
    "# utilizando la funcion stepwise_selection de la libreria dmba se seleciona las mejores varuables \n",
    "best_model, best_variables = stepwise_selection(variables, train_model, score_model, \n",
    "                                                verbose=True)\n",
    "\n",
    "# Imprimir resultados\n",
    "print()\n",
    "print(f'Intercept: {best_model.intercept_}')\n",
    "print('Coefficients:')\n",
    "for name, coef in zip(best_variables, best_model.coef_):\n",
    "    print(f' {name}: {round(coef,4)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el modelo final incluye las variables x1,x3,x4 La inclusión de X2 no mejoró el modelo, este enfoque optimiza tanto el ajuste como la complejidad del modelo. Un modelo más simple, que solo incluya variables relevantes, no solo facilita la interpretación, sino que también reduce el riesgo de sobreajuste, donde el modelo se ajusta demasiado a los datos de entrenamiento y pierde capacidad de generalización en nuevos datos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
