{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression  \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from dmba import stepwise_selection\n",
    "from dmba import AIC_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='C:/Users/andre/Downloads/laboral.csv'\n",
    "df=pd.read_csv(url,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Emplee el análisis de regresión lineal múltiple que explique la habilidad laboral en términos de las variables res-tantes (actuando como predictoras Xi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   129.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 01 Oct 2024</td> <th>  Prob (F-statistic):</th> <td>5.26e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:29:44</td>     <th>  Log-Likelihood:    </th> <td> -67.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    25</td>      <th>  AIC:               </th> <td>   145.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    20</td>      <th>  BIC:               </th> <td>   152.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>    0.2957</td> <td>    0.044</td> <td>    6.725</td> <td> 0.000</td> <td>    0.204</td> <td>    0.387</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>    <td>    0.0483</td> <td>    0.057</td> <td>    0.853</td> <td> 0.404</td> <td>   -0.070</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td>    1.3060</td> <td>    0.164</td> <td>    7.959</td> <td> 0.000</td> <td>    0.964</td> <td>    1.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X4</th>    <td>    0.5198</td> <td>    0.132</td> <td>    3.940</td> <td> 0.001</td> <td>    0.245</td> <td>    0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -124.3818</td> <td>    9.941</td> <td>  -12.512</td> <td> 0.000</td> <td> -145.119</td> <td> -103.645</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.256</td> <th>  Durbin-Watson:     </th> <td>   1.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.196</td> <th>  Jarque-Bera (JB):  </th> <td>   1.419</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.139</td> <th>  Prob(JB):          </th> <td>   0.492</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 1.867</td> <th>  Cond. No.          </th> <td>2.47e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.47e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        Y         & \\textbf{  R-squared:         } &     0.963   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.955   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     129.7   \\\\\n",
       "\\textbf{Date:}             & Tue, 01 Oct 2024 & \\textbf{  Prob (F-statistic):} &  5.26e-14   \\\\\n",
       "\\textbf{Time:}             &     22:29:44     & \\textbf{  Log-Likelihood:    } &   -67.951   \\\\\n",
       "\\textbf{No. Observations:} &          25      & \\textbf{  AIC:               } &     145.9   \\\\\n",
       "\\textbf{Df Residuals:}     &          20      & \\textbf{  BIC:               } &     152.0   \\\\\n",
       "\\textbf{Df Model:}         &           4      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{X1}    &       0.2957  &        0.044     &     6.725  &         0.000        &        0.204    &        0.387     \\\\\n",
       "\\textbf{X2}    &       0.0483  &        0.057     &     0.853  &         0.404        &       -0.070    &        0.166     \\\\\n",
       "\\textbf{X3}    &       1.3060  &        0.164     &     7.959  &         0.000        &        0.964    &        1.648     \\\\\n",
       "\\textbf{X4}    &       0.5198  &        0.132     &     3.940  &         0.001        &        0.245    &        0.795     \\\\\n",
       "\\textbf{const} &    -124.3818  &        9.941     &   -12.512  &         0.000        &     -145.119    &     -103.645     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  3.256 & \\textbf{  Durbin-Watson:     } &    1.148  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.196 & \\textbf{  Jarque-Bera (JB):  } &    1.419  \\\\\n",
       "\\textbf{Skew:}          &  0.139 & \\textbf{  Prob(JB):          } &    0.492  \\\\\n",
       "\\textbf{Kurtosis:}      &  1.867 & \\textbf{  Cond. No.          } & 2.47e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.47e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.963\n",
       "Model:                            OLS   Adj. R-squared:                  0.955\n",
       "Method:                 Least Squares   F-statistic:                     129.7\n",
       "Date:                Tue, 01 Oct 2024   Prob (F-statistic):           5.26e-14\n",
       "Time:                        22:29:44   Log-Likelihood:                -67.951\n",
       "No. Observations:                  25   AIC:                             145.9\n",
       "Df Residuals:                      20   BIC:                             152.0\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "X1             0.2957      0.044      6.725      0.000       0.204       0.387\n",
       "X2             0.0483      0.057      0.853      0.404      -0.070       0.166\n",
       "X3             1.3060      0.164      7.959      0.000       0.964       1.648\n",
       "X4             0.5198      0.132      3.940      0.001       0.245       0.795\n",
       "const       -124.3818      9.941    -12.512      0.000    -145.119    -103.645\n",
       "==============================================================================\n",
       "Omnibus:                        3.256   Durbin-Watson:                   1.148\n",
       "Prob(Omnibus):                  0.196   Jarque-Bera (JB):                1.419\n",
       "Skew:                           0.139   Prob(JB):                        0.492\n",
       "Kurtosis:                       1.867   Cond. No.                     2.47e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.47e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome='Y'\n",
    "modelo=sm.OLS(df[outcome],df[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_1=modelo.fit()\n",
    "resultado_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x1: por cada aumento de una unidad en x1, la variable Y aumenta 0.2957, esto sugiere una relacion positiva en X1,y, para x2 aumenta un 0.0483 el cual tambien sugiere una relacion positiva resaltando tambien que el coeficiente de x2 es el mas pequeño de todas las X, coefciente x4 es de 0.5198 lo que tambien indica una relacion positiva, aunque mas fuerte que x1, y por ultimo x3 muestra la relacion mas fuerte positiva 1.3060 sugiriendo que un aumento en x4 tiene un impacto mayor en la habilidad laboral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Identifique observaciones que puedan considerarse problemáticas (datos atípicos, puntos de balanceo e influ- yentes) y analice si debe eliminarlas de su conjunto de datos o no, justifique. Repita la construcción del modelode regresión si eliminó observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea un modelo de regresión lineal  usando 'outcome' \n",
    "#como variable dependiente y las variables independientes X1, X2, X3 y X4.\n",
    "modelo=sm.OLS(df[outcome],df[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado=modelo.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores atipicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "\n",
    "#Crea un objeto de influencia a partir de los resultados del modelo de regresión\n",
    "influencia=OLSInfluence(resultado)\n",
    "#Extrae los residuos estandarizados del modelo\n",
    "residuals=influencia.resid_studentized_internal\n",
    "# Localiza la fila del DataFrame con el residuo estandarizado más alto y bajo\n",
    "residuo_max=df.loc[residuals.idxmax(),:]\n",
    "residuo_min=df.loc[residuals.idxmin(),:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el valor atipico minimo en la variable Y es 76 el valor atipico maximo en la variable Y es 100 \n"
     ]
    }
   ],
   "source": [
    "#Extrae el valor del resultado (Y) correspondiente al residuo mínimo y maximo\n",
    "outlier_min=residuo_min[outcome]\n",
    "outlier_maximo=residuo_max[outcome]\n",
    "\n",
    "df_filtrado = df[(df[outcome] == outlier_min) | (df[outcome] == outlier_maximo)]\n",
    "\n",
    "print(f'el valor atipico minimo en la variable Y es {outlier_min}\\\n",
    " el valor atipico maximo en la variable Y es {outlier_maximo} '      )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los valores atípicos en la variable Y, con un mínimo de 76 y un máximo de 100, indican que hay puntos extremos extraídos de los residuos estandarizados del modelo, que podrían influir en el análisis de los datos. Es importante considerar el contexto de estos valores y su impacto en las estadísticas descriptivas para obtener una comprensión más precisa de la variable Y\n",
    "\n",
    "los valores atipicos filtrados en el dataframe son valores Y 76 y 100 con indixe 3 y 16 respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>101</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>104</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "3    76  101  117   93   95\n",
       "16  100  104   83  100  102"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores atipicos filtrados en el data set \n",
    "df_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valores influyentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtiene las distancias de Cook para cada observación\n",
    "cooks_d = influencia.cooks_distance[0]\n",
    "#Calcula el umbral para identificar puntos influyentes\n",
    "umbral=4/(len(df['Y'])-(df.shape[1]-1))\n",
    "# Identifica los índices de las observaciones \n",
    "# cuya distancia de Cook excede el umbral definido\n",
    "puntos_de_influencia=np.where(cooks_d>umbral)[0]\n",
    "#Extrae las distancias de Cook para esos puntos influyentes\n",
    "cooks_d[puntos_de_influencia]\n",
    "#Filtra el DataFrame para obtener las observaciones influyentes\n",
    "observaciones_influyentes = df.iloc[puntos_de_influencia]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "el valor influyente tiene un impacto desproporcionado en los resultados de un análisis. Estos valores pueden alterar significativamente las estimaciones de parámetros, los residuos y otros resultados del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para la observacion 0.191284 es un valor influyente en el modelo ya que esta por encima del valor del umbral 0.19047619, el valor en el dataframe correspondiente seria el indice 15,  con datos 109\t109\t129\t102\t108 con variables Y\tX1\tX2\tX3\tX4 respectivamente, las posibles acciones aconsiderar es eliminar las observaciones SI SON errores, mantener las observaciones y ver como afectan al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>109</td>\n",
       "      <td>109</td>\n",
       "      <td>129</td>\n",
       "      <td>102</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y   X1   X2   X3   X4\n",
       "15  109  109  129  102  108"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valores influyentes filtrados data set\n",
    "observaciones_influyentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "punto de balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral_leverage = 2 * (df[['X1', 'X2', 'X3', 'X4']].shape[1] / len(df))\n",
    "leverage = influencia.hat_matrix_diag\n",
    "\n",
    "# Identificar los puntos de balanceo\n",
    "puntos_de_balanceo = np.where(leverage > umbral_leverage)[0]\n",
    "\n",
    "# Filtrar el DataFrame para obtener las observaciones de balanceo\n",
    "observaciones_balanceo = df.iloc[puntos_de_balanceo]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los puntos de balanceo es donde hay un cambio significativo en la dirección de una relación o tendencia, los puntos encontrados se refieren a un cambio en una de las variables independientes (X1, X2, X3 o X4) que afecta a la variable dependiente (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELIMINAR DATOS ATIPICOS Y INFLUYENTES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este estudio, se llevaron a cabo tres modelos de regresión lineal para analizar el conjunto de datos, abordando tanto la inclusión como la exclusión de datos atípicos e influyentes. En la primera fase, se desarrolló un modelo utilizando todos los datos disponibles, lo que permitió observar la tendencia general y la relación entre las variables. Posteriormente, se realizo el modelos con datos atipicos eliminados y por ultimo un modelos borrando los datos influyentes Esta metodología nos permitió comparar la robustez de los tres enfoques y evaluar cómo la presencia de estos datos extremos puede afectar la interpretación de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar=df.copy()\n",
    "# se eliminan los valores atipicos encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar.drop(index=[3, 16], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_2=sm.OLS(df_eliminar[outcome],df_eliminar[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_2=modelo_2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se crea una copia del data set \n",
    "df_eliminar_2=df.copy()\n",
    "# se eliminan los valores atipicos encontrados y se revisa de nuevo el modelo \n",
    "df_eliminar_2.drop(index=[15], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_3=sm.OLS(df_eliminar_2[outcome],df_eliminar_2[['X1','X2','X3','X4']].assign(const=1))\n",
    "resultado_3=modelo_3.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuadro resumen de los indicadores de los 3 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resultado1</th>\n",
       "      <th>resultado2</th>\n",
       "      <th>resultado_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2</th>\n",
       "      <td>0.962892</td>\n",
       "      <td>0.971449</td>\n",
       "      <td>0.966514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2 ajus</th>\n",
       "      <td>0.955470</td>\n",
       "      <td>0.965105</td>\n",
       "      <td>0.959464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f stad</th>\n",
       "      <td>129.741157</td>\n",
       "      <td>153.114579</td>\n",
       "      <td>137.099986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIC</th>\n",
       "      <td>145.901138</td>\n",
       "      <td>130.072863</td>\n",
       "      <td>138.187575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bic</th>\n",
       "      <td>151.995517</td>\n",
       "      <td>135.750334</td>\n",
       "      <td>144.077845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         resultado1  resultado2  resultado_3\n",
       "r2         0.962892    0.971449     0.966514\n",
       "r2 ajus    0.955470    0.965105     0.959464\n",
       "f stad   129.741157  153.114579   137.099986\n",
       "AIC      145.901138  130.072863   138.187575\n",
       "Bic      151.995517  135.750334   144.077845"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadro = {\n",
    "    'resultado1': {'r2': resultado_1.rsquared, 'r2 ajus':resultado_1.rsquared_adj\n",
    "    ,'f stad':resultado_1.fvalue,'AIC':resultado_1.aic,'Bic': resultado_1.bic},\n",
    "    'resultado2': {'r2': resultado_2.rsquared, 'r2 ajus':resultado_2.rsquared_adj\n",
    "    ,'f stad':resultado_2.fvalue,'AIC':resultado_2.aic,\n",
    "    'Bic': resultado_2.bic,\n",
    "    }, 'resultado_3': {'r2': resultado_3.rsquared, 'r2 ajus':resultado_3.rsquared_adj\n",
    "      ,'f stad':resultado_3.fvalue,'AIC':resultado_3.aic,\n",
    "    'Bic': resultado_3.bic              \n",
    "    \n",
    "}}\n",
    "resumen=pd.DataFrame(cuadro)\n",
    "resumen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclucion punto dos \n",
    "\n",
    "En el análisis de los tres modelos de regresión lineal, se observa que tanto el R2 como el R2 ajustado presentan variaciones mínimas entre los modelos que incluyen datos atípicos y aquellos que los excluyen.  oscilando entre 0.962892 y 0.971449, y el R2 ajustado también muestra un comportamiento similar, con valores que varían entre 0.955470 y 0.965105.\n",
    "\n",
    "Estos resultados indican que la inclusión de los datos atípicos e influyentes no afecta de manera significativa la capacidad explicativa de los modelos. Dado que las métricas de ajuste no varían considerablemente, se puede concluir que eliminar estos datos no es necesario para mantener la robustez del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Realice la prueba de significancia del modelo, interprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se saca el p valor del modelo\n",
    "p_value_modelo = resultado_1.f_pvalue\n",
    "\n",
    "# Obtener coeficientes y valores p\n",
    "coeficientes = resultado_1.params\n",
    "valores_p = resultado_1.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un valor p de 5.26×10−14  esta por debajo del umbral común de 0.05, Esto sugiere que el modelo es significativo en su conjunto y que las variables de X están explicando variabilidad en Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " por otro lado el R2 con un valor aproximadamente del 96.29% de la variabilidad de la variable dependiente,se puede explicar que el modelo tiene un buen ajuste a los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se evaluo las variables x en funcion de los criterios valor p y el coeficiente, siendo el valor p como indicador principal de significancia, en el que se considera el valor p inferior de 0.05  una variable con relevancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1       0.000\n",
    "\n",
    "X2       0.404\n",
    "\n",
    "X3       0.000\n",
    "\n",
    "X4       0.001\n",
    "\n",
    "el valor p para x1 y x3 es de 0.000, dado que el valor p es menor a 0.05 existe evidencia para concluir que x1 y x3 tiene un efecto significativo en la habilidad laboral, x2  siguen una tendencia de un un valor p de 0.404  respectivamente, indicando que existe un efecto significativo en la habilidad laboral, y para x4 muestra una relacion positiva con un valor p de 0.001.\n",
    "\n",
    "esto sugiere que las variables mas relevantes para el modelos es x1, x3 y x4.\n",
    "\n",
    "los coeficientes\n",
    "\n",
    "X1       0.2957\n",
    "\n",
    "X2       0.0483\n",
    "\n",
    "X3       1.3060\n",
    "\n",
    "X4       0.5198\n",
    "\n",
    "Todas las variables tienen coeficientes positivos,sin embargo X3 tiene el coeficiente más alto, indicando que es la variable con el efecto más fuerte sobre Y\n",
    "\n",
    "conclucion \n",
    "\n",
    "el análisis revela que X1, X3 y X4 son variables significativas en la habilidad laboral, con X3 mostrando el efecto más fuerte. \n",
    "\n",
    "La evidencia sugiere que centrarse en mejorar o entender mejor X1, X3 y X4 podría tener un impacto notable en la habilidad laboral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtener el coeficiente de determinación y el coeficiente de determinación ajustado. Interprete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Realice una selección e variables por el método que prefiera, tome decisiones, explique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función se encarga de calcular una medida de ajuste del modelo llamada AIC (Akaike Information Criterion), que ayuda a evaluar qué tan bien un modelo se ajusta a los datos en comparación con otros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la selecccion de las variables sera por medio del criterio AIC, el cual  es útil porque equilibra la mejora en el ajuste del modelo al agregar variables con la necesidad de mantener un modelo simple. Esto asegura que el modelo final sea capaz de generalizar bien a nuevos datos, evitando problemas de sobreajuste y favoreciendo interpretaciones más claras y efectivas.\n",
    "\n",
    "formula: AIC=2k−2ln(L)\n",
    "\n",
    "Un AIC más bajo indica un mejor modelo, teniendo en cuenta tanto el ajuste como la complejidad. Un modelo más complejo (más parámetros) puede tener un mejor ajuste, pero el AIC penaliza la complejidad para evitar el sobreajuste.\n",
    "\n",
    "por lo que un el modelo con el AIC más bajo es considerado el mejor entre los que has evaluado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: X1, X2, X3, X4\n",
      "Start: score=230.25, constant\n",
      "Step: score=183.42, add X3\n",
      "Step: score=158.67, add X1\n",
      "Step: score=146.79, add X4\n",
      "Step: score=146.79, unchanged None\n",
      "\n",
      "Intercept: -124.200\n",
      "Coefficients:\n",
      " X3: 1.357\n",
      " X1: 0.296\n",
      " X4: 0.517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Definir la variable dependiente\n",
    "y = df[outcome]\n",
    "\n",
    "# Definir las variables independientes\n",
    "variables = ['X1', 'X2', 'X3', 'X4']\n",
    "\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[variables], y)  # Ajustar el modelo con las variables X1, X2, X3, X4\n",
    "    return model\n",
    "\n",
    "def score_model(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(y, [y.mean()] * len(y), model, df=5)\n",
    "    return AIC_score(y, model.predict(df[variables]), model)  # Calcular el AIC usando las predicciones del modelo\n",
    "\n",
    "# Aquí se pasan las variables específicas para la selección\n",
    "best_model, best_variables = stepwise_selection(variables, train_model, score_model, \n",
    "                                                verbose=True)\n",
    "\n",
    "# Imprimir resultados\n",
    "print()\n",
    "print(f'Intercept: {best_model.intercept_:.3f}')\n",
    "print('Coefficients:')\n",
    "for name, coef in zip(best_variables, best_model.coef_):\n",
    "    print(f' {name}: {coef:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
