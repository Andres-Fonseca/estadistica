{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ruta utilizando `/` en lugar de `\\`\n",
    "url = 'C:/Users/andre/OneDrive/Documentos/ciencia de datos/df_proyecto/df_proyecto_1.xlsx'\n",
    "df = pd.read_excel(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Campos Originales\n",
    "- **orden**: Identificador único de la orden.\n",
    "- **linea**: Número de línea dentro de la orden.\n",
    "- **entrega**: Número de entrega asociada a la orden.\n",
    "- **orden_larga**: Número largo o alternativo de la orden.\n",
    "- **codigo**: Código único asociado al producto o artículo de la orden.\n",
    "- **TNXDTE_15**: Fecha en que se procesó la orden.\n",
    "- **pais**: País de origen del pedido.\n",
    "- **CreationDate**: Fecha de creación de la orden.\n",
    "- **fecha_aproximada**: Fecha estimada de entrega de la orden.\n",
    "- **mes_aproximado**:  Mes estimado para la entrega.\n",
    "- **nit_proveedor**: Número de Identificación Tributaria (NIT) del proveedor.\n",
    "- **nombre_cliente**: Nombre del cliente que realizó la orden.\n",
    "- **cantidad**: Cantidad de productos o unidades en la orden.\n",
    "- **forma_envio**: Método de envío utilizado para la entrega.\n",
    "- **moneda**: Moneda en la que se facturó la orden.\n",
    "- **categoria**: Categoría del producto en la orden.\n",
    "- **unidad_de_medida/U_codigo**: Unidad de medida utilizada para la cantidad del producto.\n",
    "- **dias_diferencia_entrega**: Diferencia en días entre la fecha de entrega estimada y la fecha real de entrega.\n",
    "- **cumplio**: Indicador de si la entrega cumplió con los tiempos estimados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.LIMPIEZA DE DATOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1.datos generales data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el data set tiene 9639 datos \n",
      "el data set tiene 21 variables \n"
     ]
    }
   ],
   "source": [
    "numero_de_datos=df.shape[0]\n",
    "numero_de_features=df.shape[1]\n",
    "print(f'el data set tiene {numero_de_datos} datos ')\n",
    "print(f'el data set tiene {numero_de_features} variables ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el data set tiene 11 variables categoricas\n"
     ]
    }
   ],
   "source": [
    "#variables categóricas\n",
    "df_cat = df.select_dtypes(include = [\"object\", 'category']).columns.tolist()\n",
    "print(f'el data set tiene {len(df_cat)} variables categoricas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el data set tiene 6 variables numericas\n"
     ]
    }
   ],
   "source": [
    "df_num=df.select_dtypes(include = ['float64','float64','int32','int64']).columns.tolist()\n",
    "print(f'el data set tiene {len(df_num)} variables numericas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el data set tiene 4 variables de fecha\n"
     ]
    }
   ],
   "source": [
    "df_fecha=df.select_dtypes(include = ['datetime64[ns]']).columns.tolist()\n",
    "print(f'el data set tiene {len(df_fecha)} variables de fecha')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codigo: 2843\n",
      "pais: 27\n",
      "dia_semana_aproximado: 7\n",
      "mes_aproximado: 12\n",
      "nit_proveedor: 283\n",
      "nombre_proveedor: 281\n",
      "forma_envio: 5\n",
      "moneda: 4\n",
      "categoria: 24\n",
      "unidad_de_medida/U_codigo: 5\n",
      "cumplio: 2\n"
     ]
    }
   ],
   "source": [
    "# valores unicos en las categorias \n",
    "for i in df_cat:\n",
    "    print(f'{i}: {df[i].nunique()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2.nullos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular la cantidad de valores nulos por cada columna en el DataFrame\n",
    "nullos_features = df.isnull().sum()\n",
    "\n",
    "# Calcular el total de valores nulos en todo el DataFrame sumando los nulos por cada columna\n",
    "total_nullos = sum(df.isnull().sum())\n",
    "\n",
    "# Mostrar el total de valores nulos\n",
    "total_nullos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 agragar caracteristicas y eliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la cantidad de duplicados es: 78\n"
     ]
    }
   ],
   "source": [
    "print(f'la cantidad de duplicados es: {df.duplicated().sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas duplicadas del DataFrame\n",
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar columnas específicas del DataFrame NO necesarias\n",
    "df.drop(['nit_proveedor', 'TNXDTE_15', 'linea', 'entrega', 'CreationDate', 'orden_larga', 'codigo'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se agrega la caracteristica año \n",
    "df['año']=df.fecha_entrega_real.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A la columna 'nombre_proveedor' del DataFrame df se le aplicará una transformación.\n",
    "# La función str.strip() elimina los espacios en blanco que pudieran estar\n",
    "# al inicio o al final de cada nombre en la columna 'nombre_proveedor'.\n",
    "\n",
    "df['nombre_proveedor'] = df['nombre_proveedor'].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.1  outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metodo zscore para eliminar outliers\n",
    "media = df.dias_diferencia_entrega.mean()\n",
    "desviacion_std = df.dias_diferencia_entrega.std()\n",
    "z_score = ((df.dias_diferencia_entrega - media) / desviacion_std).abs()\n",
    "outliers = df[z_score > 2]\n",
    "\n",
    "# se filtra data set de outliers\n",
    "df = df[z_score <= 2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4 DATA SET CON CATEGORIAS PAISES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se está creando una copia del DataFrame original 'df' y asignándola a una nueva variable 'df_cat_paises'.\n",
    "# Esto asegura que cualquier modificación hecha a 'df_cat_paises' no afecte al DataFrame original 'df'.\n",
    "\n",
    "df_cat_paises = df.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias_geograficas = {\n",
    "    # Asia\n",
    "    'CHINA': 'Asia',\n",
    "    'SOUTH KOREA': 'Asia',\n",
    "    'TAIWAN': 'Asia',\n",
    "    'HONG KONG': 'Asia',\n",
    "    'SINGAPORE': 'Asia',\n",
    "    'ASIA': 'Asia',\n",
    "\n",
    "    # Norteamérica\n",
    "    'ESTADOS UNIDOS': 'Norteamérica',\n",
    "    'CANADA': 'Norteamérica',\n",
    "    'MEXICO': 'Norteamérica',\n",
    "\n",
    "    # Europa\n",
    "    'ESPAÑA': 'Europa',\n",
    "    'ITALIA': 'Europa',\n",
    "    'ALEMANIA': 'Europa',\n",
    "    'UNITED KINGDOM': 'Europa',\n",
    "    'PORTUGAL': 'Europa',\n",
    "    'FINLANDIA': 'Europa',\n",
    "    'POLONIA': 'Europa',\n",
    "    'AUSTRIA': 'Europa',\n",
    "    'TURKEY': 'Europa',\n",
    "\n",
    "    # América Latina\n",
    "    'BRASIL': 'América Latina',\n",
    "    'ARGENTINA': 'América Latina',\n",
    "    'CHILE': 'América Latina',\n",
    "    'PERU': 'América Latina',\n",
    "    'ECUADOR': 'América Latina',\n",
    "    'COSTA RICA': 'América Latina',\n",
    "    'PANAMA': 'América Latina',\n",
    "\n",
    "    # Oceanía\n",
    "    'NEW ZELAND': 'Oceanía',\n",
    "\n",
    "    # Oriente Medio\n",
    "    'ISRAEL': 'Oriente Medio'\n",
    "}\n",
    "\n",
    "# Agregar columna de continente basada en el mapeo\n",
    "df_cat_paises['Continente'] = df_cat_paises['pais'].map(categorias_geograficas)\n",
    "\n",
    "#df.drop('pais', axis=1, inplace=True)\n",
    "df_cat_paises.drop(['nombre_proveedor','pais'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se guarda el DataFrame 'df_cat_paises' en un archivo CSV.\n",
    "# El archivo se guardará en la ruta especificada: 'C:/Users/andre/OneDrive/Documentos/ciencia de datos/df_proyecto/data_c_paises.csv'.\n",
    "# La opción 'index=False' asegura que no se incluya el índice del DataFrame como una columna adicional en el archivo CSV.\n",
    "\n",
    "df_cat_paises.to_csv('C:/Users/andre/OneDrive/Documentos/ciencia de datos/df_proyecto/data_c_paises.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.2 DATA SET CATEGORIA PROVEEDORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_prov=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este codigo calcula el numero de ordenes por proveedor y los años de proveedor de la empresa\n",
    "# esto con el fin sacar el promedio anual de ordenes de provision por proveedor\n",
    "\n",
    "tabla_proveedores=df_cat_prov.groupby('nombre_proveedor').agg(total_conteo=('nombre_proveedor', 'count')\\\n",
    "                                        ,años_de_ventas=('año', 'nunique')).sort_values(by='total_conteo', ascending=False).reset_index()\n",
    "\n",
    "tabla_proveedores['promedio_anual']=round(tabla_proveedores.total_conteo/tabla_proveedores.años_de_ventas,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_proveedor(row):\n",
    "    # Proveedor Estratégico: Más de 3 años y más de 60 ORDENES en promedio anual\n",
    "    if row['años_de_ventas'] > 3 and row['promedio_anual'] >= 30:\n",
    "        return 'Proveedor Estratégico'\n",
    "    # Proveedor Confiable: Más de 2 años y entre 40 y 60 ORDENES en promedio anual\n",
    "    elif row['años_de_ventas'] > 2 and 20 <= row['promedio_anual'] < 30:\n",
    "        return 'Proveedor Confiable'\n",
    "    # Proveedor Regular: Al menos 1 año y entre 15 y 40 ORDENES en promedio anual\n",
    "    elif row['años_de_ventas'] >= 1 and 3 <= row['promedio_anual'] < 20:\n",
    "        return 'Proveedor Regular'\n",
    "    # Proveedor Ocasional: Al menos 1 año y entre 3 y 15 ORDENES en promedio anual\n",
    "    elif row['años_de_ventas'] >= 1 and 1 <= row['promedio_anual'] < 3:\n",
    "        return 'Proveedor Ocasional'\n",
    "    # Proveedor Esporádico: Menos de 1 año o promedio anual menor a 3\n",
    "    else:\n",
    "        return 'Proveedor Esporádico'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una nueva columna 'cate_proveedor' en el DataFrame 'tabla_proveedores'.\n",
    "# La función 'categorizar_proveedor' se aplica a cada fila del DataFrame usando 'apply'.\n",
    "tabla_proveedores['cate_proveedor'] = tabla_proveedores.apply(categorizar_proveedor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza una fusión (merge) de los DataFrames 'df_cat_prov' y 'tabla_proveedores' en base a la columna 'nombre_proveedor'.\n",
    "# La opción 'how=\"inner\"' indica que solo se mantendrán las filas que tengan coincidencias en ambas tablas (fusión interna).\n",
    "# Esto garantiza que solo los proveedores presentes en ambos DataFrames aparecerán en el DataFrame resultante.\n",
    "\n",
    "df_cat_prov = pd.merge(df_cat_prov, tabla_proveedores, on='nombre_proveedor', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_prov=df_cat_prov[['orden','fecha_aproximada','dia_semana_aproximado','mes_aproximado','fecha_entrega_real','cantidad',\\\n",
    "                         'forma_envio','moneda','categoria','unidad_de_medida/U_codigo','dias_diferencia_entrega','cumplio','año','cate_proveedor','pais']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_prov.to_csv('C:/Users/andre/OneDrive/Documentos/ciencia de datos/df_proyecto/data_cat_prov.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.3 DATA SET CATEGORIA PROVEEDORES y PAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_=df_cat_prov.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_['Continente'] = df_c_['pais'].map(categorias_geograficas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_.drop('pais', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_.to_csv('C:/Users/andre/OneDrive/Documentos/ciencia de datos/df_proyecto/data_cat_total.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4.4 DATA SET PROVEEDORES INCUMPLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prove_incum=df_c_[df_c_.cumplio=='NO CUMPLIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prove_incum.to_csv('C:/Users/andre/OneDrive/Documentos/ciencia de datos/df_proyecto/data_prove_incum.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
